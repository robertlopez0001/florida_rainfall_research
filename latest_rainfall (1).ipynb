{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354bf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "\n",
    "def scraper(url):\n",
    "    stations = [\"Alachua_260\", \"Apopka_320\", \"Arcadia_490\", \"Avalon_304\", \"Babson Park_400\", \"Balm_350\", \"Belle Glade_410\", \"Bristol_190\", \"Bronson_230\", \n",
    "                \"Brooksville South_315\", \"Carrabelle_150\", \"Citra_250\", \"Clewiston_405\", \"Dade City_311\", \"DeFuniak Springs_120\", \"Dover\", \n",
    "                \"Fort Lauderdale_420\", \"Fort Pierce_430\", \"Hastings_270\", \"Homestead_440\", \"Immokalee_450\", \"Jay_110\", \"Joshua_241\", \"Kenansville_340\", \n",
    "                \"Lake Alfred_330\", \"Lecanto_275\", \"Live Oak_170\", \"Macclenny_180\", \"Marianna_130\", \"Mayo_121\", \"Monticello_160\",\"North Port_480\", \"Ocklawaha_280\",\n",
    "                \"Okahumpka_303\",\"Okeechobee_455\",\"Ona_380\",\"Palmdale_460\",\"Panama City_125\",\"Pierson_290\",\"Poinciana_335\",\"Putnam Hall_240\",\"Quincy_140\",\"Sebring_470\",\n",
    "                \"St. Lucie West_435\",\"Tiger Creek_395\",\"Umatilla_302\",\"Wellington_425\"]\n",
    "    \n",
    "    years = [\"2021.csv\", \"2022.csv\", \"2023.csv\"]\n",
    "    dataframe = []\n",
    "    for station in stations:\n",
    "        for year in years:\n",
    "            file_url = url + station + \"/\" + year\n",
    "            response = requests.get(file_url)\n",
    "            if response.status_code == 200:\n",
    "                df = pd.read_csv(io.StringIO(response.text))\n",
    "                dataframe.append(df)\n",
    "          \n",
    "    final_df = pd.concat(dataframe, ignore_index=True)    \n",
    "    return final_df\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7632c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged: Alachua_2602021.csv\n",
      "merged: Alachua_2602022.csv\n",
      "merged: Alachua_2602023.csv\n",
      "merged: Apopka_3202021.csv\n",
      "merged: Apopka_3202022.csv\n",
      "merged: Apopka_3202023.csv\n",
      "merged: Arcadia_4902021.csv\n",
      "merged: Arcadia_4902022.csv\n",
      "merged: Arcadia_4902023.csv\n",
      "merged: Avalon_3042021.csv\n",
      "merged: Avalon_3042022.csv\n",
      "merged: Avalon_3042023.csv\n",
      "Failed to merge: Babson Park_4002021.csv\n",
      "merged: Babson Park_4002022.csv\n",
      "merged: Babson Park_4002023.csv\n",
      "merged: Balm_3502021.csv\n",
      "merged: Balm_3502022.csv\n",
      "merged: Balm_3502023.csv\n",
      "merged: Belle Glade_4102021.csv\n",
      "merged: Belle Glade_4102022.csv\n",
      "merged: Belle Glade_4102023.csv\n",
      "Failed to merge: Bristol_1902021.csv\n",
      "merged: Bristol_1902022.csv\n",
      "merged: Bristol_1902023.csv\n",
      "merged: Bronson_2302021.csv\n",
      "merged: Bronson_2302022.csv\n",
      "merged: Bronson_2302023.csv\n",
      "merged: Brooksville South_3152021.csv\n",
      "merged: Brooksville South_3152022.csv\n",
      "merged: Brooksville South_3152023.csv\n",
      "merged: Carrabelle_1502021.csv\n",
      "merged: Carrabelle_1502022.csv\n",
      "merged: Carrabelle_1502023.csv\n",
      "merged: Citra_2502021.csv\n",
      "merged: Citra_2502022.csv\n",
      "merged: Citra_2502023.csv\n",
      "merged: Clewiston_4052021.csv\n",
      "merged: Clewiston_4052022.csv\n",
      "merged: Clewiston_4052023.csv\n",
      "merged: Dade City_3112021.csv\n",
      "merged: Dade City_3112022.csv\n",
      "merged: Dade City_3112023.csv\n",
      "merged: DeFuniak Springs_1202021.csv\n",
      "merged: DeFuniak Springs_1202022.csv\n",
      "merged: DeFuniak Springs_1202023.csv\n",
      "Failed to merge: Dover2021.csv\n",
      "Failed to merge: Dover2022.csv\n",
      "Failed to merge: Dover2023.csv\n",
      "merged: Fort Lauderdale_4202021.csv\n",
      "merged: Fort Lauderdale_4202022.csv\n",
      "merged: Fort Lauderdale_4202023.csv\n",
      "merged: Fort Pierce_4302021.csv\n",
      "merged: Fort Pierce_4302022.csv\n",
      "merged: Fort Pierce_4302023.csv\n",
      "merged: Hastings_2702021.csv\n",
      "merged: Hastings_2702022.csv\n",
      "merged: Hastings_2702023.csv\n",
      "merged: Homestead_4402021.csv\n",
      "merged: Homestead_4402022.csv\n",
      "merged: Homestead_4402023.csv\n",
      "merged: Immokalee_4502021.csv\n",
      "merged: Immokalee_4502022.csv\n",
      "merged: Immokalee_4502023.csv\n",
      "merged: Jay_1102021.csv\n",
      "merged: Jay_1102022.csv\n",
      "merged: Jay_1102023.csv\n",
      "merged: Joshua_2412021.csv\n",
      "merged: Joshua_2412022.csv\n",
      "merged: Joshua_2412023.csv\n",
      "merged: Kenansville_3402021.csv\n",
      "merged: Kenansville_3402022.csv\n",
      "merged: Kenansville_3402023.csv\n",
      "merged: Lake Alfred_3302021.csv\n",
      "merged: Lake Alfred_3302022.csv\n",
      "merged: Lake Alfred_3302023.csv\n",
      "merged: Lecanto_2752021.csv\n",
      "merged: Lecanto_2752022.csv\n",
      "merged: Lecanto_2752023.csv\n",
      "merged: Live Oak_1702021.csv\n",
      "merged: Live Oak_1702022.csv\n",
      "merged: Live Oak_1702023.csv\n",
      "merged: Macclenny_1802021.csv\n",
      "merged: Macclenny_1802022.csv\n",
      "merged: Macclenny_1802023.csv\n",
      "merged: Marianna_1302021.csv\n",
      "merged: Marianna_1302022.csv\n",
      "merged: Marianna_1302023.csv\n",
      "merged: Mayo_1212021.csv\n",
      "merged: Mayo_1212022.csv\n",
      "merged: Mayo_1212023.csv\n",
      "merged: Monticello_1602021.csv\n",
      "merged: Monticello_1602022.csv\n",
      "merged: Monticello_1602023.csv\n",
      "merged: North Port_4802021.csv\n",
      "merged: North Port_4802022.csv\n",
      "merged: North Port_4802023.csv\n",
      "merged: Ocklawaha_2802021.csv\n",
      "merged: Ocklawaha_2802022.csv\n",
      "merged: Ocklawaha_2802023.csv\n",
      "merged: Okahumpka_3032021.csv\n",
      "merged: Okahumpka_3032022.csv\n",
      "merged: Okahumpka_3032023.csv\n",
      "merged: Okeechobee_4552021.csv\n",
      "merged: Okeechobee_4552022.csv\n",
      "merged: Okeechobee_4552023.csv\n",
      "merged: Ona_3802021.csv\n",
      "merged: Ona_3802022.csv\n",
      "merged: Ona_3802023.csv\n",
      "merged: Palmdale_4602021.csv\n",
      "merged: Palmdale_4602022.csv\n",
      "merged: Palmdale_4602023.csv\n",
      "Failed to merge: Panama City_1252021.csv\n",
      "merged: Panama City_1252022.csv\n",
      "merged: Panama City_1252023.csv\n",
      "merged: Pierson_2902021.csv\n",
      "merged: Pierson_2902022.csv\n",
      "merged: Pierson_2902023.csv\n",
      "Failed to merge: Poinciana_3352021.csv\n",
      "merged: Poinciana_3352022.csv\n",
      "merged: Poinciana_3352023.csv\n",
      "merged: Putnam Hall_2402021.csv\n",
      "merged: Putnam Hall_2402022.csv\n",
      "merged: Putnam Hall_2402023.csv\n",
      "merged: Quincy_1402021.csv\n",
      "merged: Quincy_1402022.csv\n",
      "merged: Quincy_1402023.csv\n",
      "merged: Sebring_4702021.csv\n",
      "merged: Sebring_4702022.csv\n",
      "merged: Sebring_4702023.csv\n",
      "merged: St. Lucie West_4352021.csv\n",
      "merged: St. Lucie West_4352022.csv\n",
      "merged: St. Lucie West_4352023.csv\n",
      "Failed to merge: Tiger Creek_3952021.csv\n",
      "merged: Tiger Creek_3952022.csv\n",
      "merged: Tiger Creek_3952023.csv\n",
      "merged: Umatilla_3022021.csv\n",
      "merged: Umatilla_3022022.csv\n",
      "merged: Umatilla_3022023.csv\n",
      "merged: Wellington_4252021.csv\n",
      "merged: Wellington_4252022.csv\n",
      "merged: Wellington_4252023.csv\n"
     ]
    }
   ],
   "source": [
    "data = scraper(\"https://fawn.ifas.ufl.edu/data/fawnpub/daily_summaries/BY_STATION/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efcf7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=data.columns[-150:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24303811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['StationID', 'Date Time', 'Soil Temp (C) Avg', 'Soil Temp (C) Min',\n",
       "       'Soil Temp (C) Max', 'Temp @ 60cm (C) Avg', 'Temp @ 60cm (C) Min',\n",
       "       'Temp @ 60cm (C) Max', 'Temp @ 2m (C) Avg', 'Temp @ 2m (C) Min',\n",
       "       'Temp @ 2m (C) Max', 'Temp @ 10m (C) Avg', 'Temp @ 10m (C) Min',\n",
       "       'Temp @ 10m (C) Max', 'Relative Humidity (%) Avg',\n",
       "       'Dew Point Temp (C) Avg', 'Dew Point Temp (C) Min',\n",
       "       'Dew Point Temp (C) Max', 'Rainfall Amount (in) Sum',\n",
       "       'Wind Speed (mph) Avg', 'Wind Speed (mph) Max',\n",
       "       'Wind Direction (deg) Avg', 'Solar Radiation (w/m2) Avg',\n",
       "       'Solar Radiation (MJ/m2) Sum', 'ETo Grass (mm) Avg',\n",
       "       'Number of Observations'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9401e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns= [\"StationID\", \"Date Time\", \"Number of Observations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cfddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc552d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rainfall -> 46.51\n",
      "Min Rainfall -> 0.0\n"
     ]
    }
   ],
   "source": [
    "# lets find the minimum and maximum values of rainfall in our dataset so that we can create a range\n",
    "min_rainfall = data['Rainfall Amount (in) Sum'].min()\n",
    "max_rainfall = data['Rainfall Amount (in) Sum'].max()\n",
    "print(f'Max Rainfall -> {max_rainfall}')\n",
    "print(f'Min Rainfall -> {min_rainfall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63559cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Temp (C) Avg</th>\n",
       "      <th>Soil Temp (C) Min</th>\n",
       "      <th>Soil Temp (C) Max</th>\n",
       "      <th>Temp @ 60cm (C) Avg</th>\n",
       "      <th>Temp @ 60cm (C) Min</th>\n",
       "      <th>Temp @ 60cm (C) Max</th>\n",
       "      <th>Temp @ 2m (C) Avg</th>\n",
       "      <th>Temp @ 2m (C) Min</th>\n",
       "      <th>Temp @ 2m (C) Max</th>\n",
       "      <th>Temp @ 10m (C) Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Dew Point Temp (C) Avg</th>\n",
       "      <th>Dew Point Temp (C) Min</th>\n",
       "      <th>Dew Point Temp (C) Max</th>\n",
       "      <th>Rainfall Amount (in) Sum</th>\n",
       "      <th>Wind Speed (mph) Avg</th>\n",
       "      <th>Wind Speed (mph) Max</th>\n",
       "      <th>Wind Direction (deg) Avg</th>\n",
       "      <th>Solar Radiation (w/m2) Avg</th>\n",
       "      <th>Solar Radiation (MJ/m2) Sum</th>\n",
       "      <th>ETo Grass (mm) Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.02</td>\n",
       "      <td>17.02</td>\n",
       "      <td>19.40</td>\n",
       "      <td>22.98</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.53</td>\n",
       "      <td>23.24</td>\n",
       "      <td>19.87</td>\n",
       "      <td>28.18</td>\n",
       "      <td>22.82</td>\n",
       "      <td>...</td>\n",
       "      <td>19.81</td>\n",
       "      <td>19.08</td>\n",
       "      <td>21.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.43</td>\n",
       "      <td>13.50</td>\n",
       "      <td>187.08</td>\n",
       "      <td>102.84</td>\n",
       "      <td>8.885520</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.56</td>\n",
       "      <td>17.86</td>\n",
       "      <td>19.32</td>\n",
       "      <td>22.06</td>\n",
       "      <td>18.97</td>\n",
       "      <td>25.60</td>\n",
       "      <td>22.38</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.55</td>\n",
       "      <td>22.01</td>\n",
       "      <td>...</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.60</td>\n",
       "      <td>21.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.30</td>\n",
       "      <td>11.64</td>\n",
       "      <td>206.36</td>\n",
       "      <td>56.00</td>\n",
       "      <td>4.838430</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.44</td>\n",
       "      <td>16.76</td>\n",
       "      <td>19.23</td>\n",
       "      <td>15.99</td>\n",
       "      <td>6.22</td>\n",
       "      <td>21.15</td>\n",
       "      <td>16.26</td>\n",
       "      <td>7.12</td>\n",
       "      <td>21.46</td>\n",
       "      <td>16.30</td>\n",
       "      <td>...</td>\n",
       "      <td>13.10</td>\n",
       "      <td>6.31</td>\n",
       "      <td>20.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.23</td>\n",
       "      <td>9.81</td>\n",
       "      <td>278.66</td>\n",
       "      <td>112.29</td>\n",
       "      <td>9.701800</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.42</td>\n",
       "      <td>13.96</td>\n",
       "      <td>16.74</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2.67</td>\n",
       "      <td>17.87</td>\n",
       "      <td>9.17</td>\n",
       "      <td>3.49</td>\n",
       "      <td>17.23</td>\n",
       "      <td>9.38</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.26</td>\n",
       "      <td>250.10</td>\n",
       "      <td>146.77</td>\n",
       "      <td>12.680800</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.09</td>\n",
       "      <td>12.54</td>\n",
       "      <td>15.71</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>19.85</td>\n",
       "      <td>10.01</td>\n",
       "      <td>2.51</td>\n",
       "      <td>19.30</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.50</td>\n",
       "      <td>15.19</td>\n",
       "      <td>278.38</td>\n",
       "      <td>129.59</td>\n",
       "      <td>11.196400</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>27.42</td>\n",
       "      <td>26.74</td>\n",
       "      <td>28.04</td>\n",
       "      <td>25.79</td>\n",
       "      <td>21.53</td>\n",
       "      <td>33.12</td>\n",
       "      <td>25.72</td>\n",
       "      <td>22.05</td>\n",
       "      <td>32.02</td>\n",
       "      <td>25.68</td>\n",
       "      <td>...</td>\n",
       "      <td>24.16</td>\n",
       "      <td>21.67</td>\n",
       "      <td>26.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.90</td>\n",
       "      <td>12.30</td>\n",
       "      <td>100.05</td>\n",
       "      <td>155.86</td>\n",
       "      <td>13.325607</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42697</th>\n",
       "      <td>27.46</td>\n",
       "      <td>26.86</td>\n",
       "      <td>28.00</td>\n",
       "      <td>26.29</td>\n",
       "      <td>22.82</td>\n",
       "      <td>33.19</td>\n",
       "      <td>26.34</td>\n",
       "      <td>23.33</td>\n",
       "      <td>32.45</td>\n",
       "      <td>26.37</td>\n",
       "      <td>...</td>\n",
       "      <td>25.02</td>\n",
       "      <td>22.75</td>\n",
       "      <td>28.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.43</td>\n",
       "      <td>15.28</td>\n",
       "      <td>120.70</td>\n",
       "      <td>126.60</td>\n",
       "      <td>10.938411</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42698</th>\n",
       "      <td>27.48</td>\n",
       "      <td>27.00</td>\n",
       "      <td>28.13</td>\n",
       "      <td>26.13</td>\n",
       "      <td>23.75</td>\n",
       "      <td>31.76</td>\n",
       "      <td>26.10</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.76</td>\n",
       "      <td>26.11</td>\n",
       "      <td>...</td>\n",
       "      <td>24.67</td>\n",
       "      <td>23.56</td>\n",
       "      <td>26.92</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.50</td>\n",
       "      <td>8.22</td>\n",
       "      <td>160.35</td>\n",
       "      <td>131.80</td>\n",
       "      <td>11.387943</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>27.58</td>\n",
       "      <td>26.98</td>\n",
       "      <td>28.06</td>\n",
       "      <td>26.16</td>\n",
       "      <td>22.78</td>\n",
       "      <td>31.11</td>\n",
       "      <td>26.35</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.38</td>\n",
       "      <td>26.32</td>\n",
       "      <td>...</td>\n",
       "      <td>25.24</td>\n",
       "      <td>23.64</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.01</td>\n",
       "      <td>171.48</td>\n",
       "      <td>118.18</td>\n",
       "      <td>10.210941</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42700</th>\n",
       "      <td>27.86</td>\n",
       "      <td>27.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>27.13</td>\n",
       "      <td>24.11</td>\n",
       "      <td>34.34</td>\n",
       "      <td>27.00</td>\n",
       "      <td>24.23</td>\n",
       "      <td>32.76</td>\n",
       "      <td>26.86</td>\n",
       "      <td>...</td>\n",
       "      <td>25.19</td>\n",
       "      <td>23.40</td>\n",
       "      <td>27.67</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.96</td>\n",
       "      <td>9.81</td>\n",
       "      <td>169.83</td>\n",
       "      <td>186.88</td>\n",
       "      <td>16.146135</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40437 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Soil Temp (C) Avg  Soil Temp (C) Min  Soil Temp (C) Max  \\\n",
       "0                  18.02              17.02              19.40   \n",
       "1                  18.56              17.86              19.32   \n",
       "2                  18.44              16.76              19.23   \n",
       "3                  15.42              13.96              16.74   \n",
       "4                  14.09              12.54              15.71   \n",
       "...                  ...                ...                ...   \n",
       "42696              27.42              26.74              28.04   \n",
       "42697              27.46              26.86              28.00   \n",
       "42698              27.48              27.00              28.13   \n",
       "42699              27.58              26.98              28.06   \n",
       "42700              27.86              27.19              28.74   \n",
       "\n",
       "       Temp @ 60cm (C) Avg  Temp @ 60cm (C) Min  Temp @ 60cm (C) Max  \\\n",
       "0                    22.98                19.53                28.53   \n",
       "1                    22.06                18.97                25.60   \n",
       "2                    15.99                 6.22                21.15   \n",
       "3                     8.89                 2.67                17.87   \n",
       "4                     9.50                 1.66                19.85   \n",
       "...                    ...                  ...                  ...   \n",
       "42696                25.79                21.53                33.12   \n",
       "42697                26.29                22.82                33.19   \n",
       "42698                26.13                23.75                31.76   \n",
       "42699                26.16                22.78                31.11   \n",
       "42700                27.13                24.11                34.34   \n",
       "\n",
       "       Temp @ 2m (C) Avg  Temp @ 2m (C) Min  Temp @ 2m (C) Max  \\\n",
       "0                  23.24              19.87              28.18   \n",
       "1                  22.38              19.62              25.55   \n",
       "2                  16.26               7.12              21.46   \n",
       "3                   9.17               3.49              17.23   \n",
       "4                  10.01               2.51              19.30   \n",
       "...                  ...                ...                ...   \n",
       "42696              25.72              22.05              32.02   \n",
       "42697              26.34              23.33              32.45   \n",
       "42698              26.10              23.86              30.76   \n",
       "42699              26.35              23.86              30.38   \n",
       "42700              27.00              24.23              32.76   \n",
       "\n",
       "       Temp @ 10m (C) Avg  ...  Dew Point Temp (C) Avg  \\\n",
       "0                   22.82  ...                   19.81   \n",
       "1                   22.01  ...                   20.14   \n",
       "2                   16.30  ...                   13.10   \n",
       "3                    9.38  ...                    4.51   \n",
       "4                   10.52  ...                    5.50   \n",
       "...                   ...  ...                     ...   \n",
       "42696               25.68  ...                   24.16   \n",
       "42697               26.37  ...                   25.02   \n",
       "42698               26.11  ...                   24.67   \n",
       "42699               26.32  ...                   25.24   \n",
       "42700               26.86  ...                   25.19   \n",
       "\n",
       "       Dew Point Temp (C) Min  Dew Point Temp (C) Max  \\\n",
       "0                       19.08                   21.31   \n",
       "1                       18.60                   21.22   \n",
       "2                        6.31                   20.18   \n",
       "3                        2.86                    7.24   \n",
       "4                        2.13                   12.36   \n",
       "...                       ...                     ...   \n",
       "42696                   21.67                   26.63   \n",
       "42697                   22.75                   28.01   \n",
       "42698                   23.56                   26.92   \n",
       "42699                   23.64                   28.00   \n",
       "42700                   23.40                   27.67   \n",
       "\n",
       "       Rainfall Amount (in) Sum  Wind Speed (mph) Avg  Wind Speed (mph) Max  \\\n",
       "0                          0.00                  7.43                 13.50   \n",
       "1                          0.00                  7.30                 11.64   \n",
       "2                          0.41                  5.23                  9.81   \n",
       "3                          0.00                  2.87                  8.26   \n",
       "4                          0.05                  4.50                 15.19   \n",
       "...                         ...                   ...                   ...   \n",
       "42696                      1.14                  4.90                 12.30   \n",
       "42697                      0.46                  4.43                 15.28   \n",
       "42698                      0.11                  3.50                  8.22   \n",
       "42699                      0.01                  2.55                  7.01   \n",
       "42700                      0.17                  2.96                  9.81   \n",
       "\n",
       "       Wind Direction (deg) Avg  Solar Radiation (w/m2) Avg  \\\n",
       "0                        187.08                      102.84   \n",
       "1                        206.36                       56.00   \n",
       "2                        278.66                      112.29   \n",
       "3                        250.10                      146.77   \n",
       "4                        278.38                      129.59   \n",
       "...                         ...                         ...   \n",
       "42696                    100.05                      155.86   \n",
       "42697                    120.70                      126.60   \n",
       "42698                    160.35                      131.80   \n",
       "42699                    171.48                      118.18   \n",
       "42700                    169.83                      186.88   \n",
       "\n",
       "       Solar Radiation (MJ/m2) Sum  ETo Grass (mm) Avg  \n",
       "0                         8.885520                1.76  \n",
       "1                         4.838430                1.38  \n",
       "2                         9.701800                1.36  \n",
       "3                        12.680800                1.06  \n",
       "4                        11.196400                1.22  \n",
       "...                            ...                 ...  \n",
       "42696                    13.325607                3.02  \n",
       "42697                    10.938411                2.71  \n",
       "42698                    11.387943                2.66  \n",
       "42699                    10.210941                2.44  \n",
       "42700                    16.146135                3.49  \n",
       "\n",
       "[40437 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e374bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q1 = np.percentile(data['Rainfall Amount (in) Sum'], 25)\n",
    "median = np.percentile(data['Rainfall Amount (in) Sum'], 50)\n",
    "q3 = np.percentile(data['Rainfall Amount (in) Sum'], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98aa2455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1298b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-float(\"inf\"), 0.01, 1.0 , float('inf')]\n",
    "        \n",
    "\n",
    "# Define labels for the bins\n",
    "labels = ['0-0.01', '0.01-1.0',float(\"inf\")]\n",
    "\n",
    "# Use pd.cut() to create the intervals\n",
    "data = data.copy()\n",
    "data.loc[:, 'zones'] = pd.cut(data['Rainfall Amount (in) Sum'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3185534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40437.000000\n",
       "mean         0.151922\n",
       "std          0.522670\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.050000\n",
       "max         46.510000\n",
       "Name: Rainfall Amount (in) Sum, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rainfall Amount (in) Sum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf58a8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.boxplot(column='Rainfall Amount (in) Sum')\n",
    "plt.ylabel('Rainfall Amount (in) Sum')\n",
    "plt.title('Box Plot of Rainfall Amount (in) Sum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c34f46e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1847\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for v in data['Rainfall Amount (in) Sum']:\n",
    "    if v >= 1.0:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab807a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     40437\n",
       "unique        3\n",
       "top       0-0.2\n",
       "freq      33774\n",
       "Name: zones, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['zones'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5911dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = pd.get_dummies(data['zones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbb578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-0.01</th>\n",
       "      <th>0.01-1.0</th>\n",
       "      <th>inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42697</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42698</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42700</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40437 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0-0.01  0.01-1.0  inf\n",
       "0           1         0    0\n",
       "1           1         0    0\n",
       "2           0         1    0\n",
       "3           1         0    0\n",
       "4           0         1    0\n",
       "...       ...       ...  ...\n",
       "42696       0         0    1\n",
       "42697       0         1    0\n",
       "42698       0         1    0\n",
       "42699       0         1    0\n",
       "42700       0         1    0\n",
       "\n",
       "[40437 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e9a23de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38590\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for v in y_encoded[float(\"inf\")]:\n",
    "    if v == 0.0:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cda3c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f220425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Temp (C) Avg</th>\n",
       "      <th>Soil Temp (C) Min</th>\n",
       "      <th>Soil Temp (C) Max</th>\n",
       "      <th>Temp @ 60cm (C) Avg</th>\n",
       "      <th>Temp @ 60cm (C) Min</th>\n",
       "      <th>Temp @ 60cm (C) Max</th>\n",
       "      <th>Temp @ 2m (C) Avg</th>\n",
       "      <th>Temp @ 2m (C) Min</th>\n",
       "      <th>Temp @ 2m (C) Max</th>\n",
       "      <th>Temp @ 10m (C) Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Relative Humidity (%) Avg</th>\n",
       "      <th>Dew Point Temp (C) Avg</th>\n",
       "      <th>Dew Point Temp (C) Min</th>\n",
       "      <th>Dew Point Temp (C) Max</th>\n",
       "      <th>Wind Speed (mph) Avg</th>\n",
       "      <th>Wind Speed (mph) Max</th>\n",
       "      <th>Wind Direction (deg) Avg</th>\n",
       "      <th>Solar Radiation (w/m2) Avg</th>\n",
       "      <th>Solar Radiation (MJ/m2) Sum</th>\n",
       "      <th>ETo Grass (mm) Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.02</td>\n",
       "      <td>17.02</td>\n",
       "      <td>19.40</td>\n",
       "      <td>22.98</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.53</td>\n",
       "      <td>23.24</td>\n",
       "      <td>19.87</td>\n",
       "      <td>28.18</td>\n",
       "      <td>22.82</td>\n",
       "      <td>...</td>\n",
       "      <td>82.11</td>\n",
       "      <td>19.81</td>\n",
       "      <td>19.08</td>\n",
       "      <td>21.31</td>\n",
       "      <td>7.43</td>\n",
       "      <td>13.50</td>\n",
       "      <td>187.08</td>\n",
       "      <td>102.84</td>\n",
       "      <td>8.885520</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.56</td>\n",
       "      <td>17.86</td>\n",
       "      <td>19.32</td>\n",
       "      <td>22.06</td>\n",
       "      <td>18.97</td>\n",
       "      <td>25.60</td>\n",
       "      <td>22.38</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.55</td>\n",
       "      <td>22.01</td>\n",
       "      <td>...</td>\n",
       "      <td>87.47</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.60</td>\n",
       "      <td>21.22</td>\n",
       "      <td>7.30</td>\n",
       "      <td>11.64</td>\n",
       "      <td>206.36</td>\n",
       "      <td>56.00</td>\n",
       "      <td>4.838430</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.44</td>\n",
       "      <td>16.76</td>\n",
       "      <td>19.23</td>\n",
       "      <td>15.99</td>\n",
       "      <td>6.22</td>\n",
       "      <td>21.15</td>\n",
       "      <td>16.26</td>\n",
       "      <td>7.12</td>\n",
       "      <td>21.46</td>\n",
       "      <td>16.30</td>\n",
       "      <td>...</td>\n",
       "      <td>83.23</td>\n",
       "      <td>13.10</td>\n",
       "      <td>6.31</td>\n",
       "      <td>20.18</td>\n",
       "      <td>5.23</td>\n",
       "      <td>9.81</td>\n",
       "      <td>278.66</td>\n",
       "      <td>112.29</td>\n",
       "      <td>9.701800</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.42</td>\n",
       "      <td>13.96</td>\n",
       "      <td>16.74</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2.67</td>\n",
       "      <td>17.87</td>\n",
       "      <td>9.17</td>\n",
       "      <td>3.49</td>\n",
       "      <td>17.23</td>\n",
       "      <td>9.38</td>\n",
       "      <td>...</td>\n",
       "      <td>76.71</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.26</td>\n",
       "      <td>250.10</td>\n",
       "      <td>146.77</td>\n",
       "      <td>12.680800</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.09</td>\n",
       "      <td>12.54</td>\n",
       "      <td>15.71</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>19.85</td>\n",
       "      <td>10.01</td>\n",
       "      <td>2.51</td>\n",
       "      <td>19.30</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>77.26</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12.36</td>\n",
       "      <td>4.50</td>\n",
       "      <td>15.19</td>\n",
       "      <td>278.38</td>\n",
       "      <td>129.59</td>\n",
       "      <td>11.196400</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>27.42</td>\n",
       "      <td>26.74</td>\n",
       "      <td>28.04</td>\n",
       "      <td>25.79</td>\n",
       "      <td>21.53</td>\n",
       "      <td>33.12</td>\n",
       "      <td>25.72</td>\n",
       "      <td>22.05</td>\n",
       "      <td>32.02</td>\n",
       "      <td>25.68</td>\n",
       "      <td>...</td>\n",
       "      <td>91.77</td>\n",
       "      <td>24.16</td>\n",
       "      <td>21.67</td>\n",
       "      <td>26.63</td>\n",
       "      <td>4.90</td>\n",
       "      <td>12.30</td>\n",
       "      <td>100.05</td>\n",
       "      <td>155.86</td>\n",
       "      <td>13.325607</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42697</th>\n",
       "      <td>27.46</td>\n",
       "      <td>26.86</td>\n",
       "      <td>28.00</td>\n",
       "      <td>26.29</td>\n",
       "      <td>22.82</td>\n",
       "      <td>33.19</td>\n",
       "      <td>26.34</td>\n",
       "      <td>23.33</td>\n",
       "      <td>32.45</td>\n",
       "      <td>26.37</td>\n",
       "      <td>...</td>\n",
       "      <td>92.80</td>\n",
       "      <td>25.02</td>\n",
       "      <td>22.75</td>\n",
       "      <td>28.01</td>\n",
       "      <td>4.43</td>\n",
       "      <td>15.28</td>\n",
       "      <td>120.70</td>\n",
       "      <td>126.60</td>\n",
       "      <td>10.938411</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42698</th>\n",
       "      <td>27.48</td>\n",
       "      <td>27.00</td>\n",
       "      <td>28.13</td>\n",
       "      <td>26.13</td>\n",
       "      <td>23.75</td>\n",
       "      <td>31.76</td>\n",
       "      <td>26.10</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.76</td>\n",
       "      <td>26.11</td>\n",
       "      <td>...</td>\n",
       "      <td>92.22</td>\n",
       "      <td>24.67</td>\n",
       "      <td>23.56</td>\n",
       "      <td>26.92</td>\n",
       "      <td>3.50</td>\n",
       "      <td>8.22</td>\n",
       "      <td>160.35</td>\n",
       "      <td>131.80</td>\n",
       "      <td>11.387943</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>27.58</td>\n",
       "      <td>26.98</td>\n",
       "      <td>28.06</td>\n",
       "      <td>26.16</td>\n",
       "      <td>22.78</td>\n",
       "      <td>31.11</td>\n",
       "      <td>26.35</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.38</td>\n",
       "      <td>26.32</td>\n",
       "      <td>...</td>\n",
       "      <td>93.90</td>\n",
       "      <td>25.24</td>\n",
       "      <td>23.64</td>\n",
       "      <td>28.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.01</td>\n",
       "      <td>171.48</td>\n",
       "      <td>118.18</td>\n",
       "      <td>10.210941</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42700</th>\n",
       "      <td>27.86</td>\n",
       "      <td>27.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>27.13</td>\n",
       "      <td>24.11</td>\n",
       "      <td>34.34</td>\n",
       "      <td>27.00</td>\n",
       "      <td>24.23</td>\n",
       "      <td>32.76</td>\n",
       "      <td>26.86</td>\n",
       "      <td>...</td>\n",
       "      <td>90.77</td>\n",
       "      <td>25.19</td>\n",
       "      <td>23.40</td>\n",
       "      <td>27.67</td>\n",
       "      <td>2.96</td>\n",
       "      <td>9.81</td>\n",
       "      <td>169.83</td>\n",
       "      <td>186.88</td>\n",
       "      <td>16.146135</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40437 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Soil Temp (C) Avg  Soil Temp (C) Min  Soil Temp (C) Max  \\\n",
       "0                  18.02              17.02              19.40   \n",
       "1                  18.56              17.86              19.32   \n",
       "2                  18.44              16.76              19.23   \n",
       "3                  15.42              13.96              16.74   \n",
       "4                  14.09              12.54              15.71   \n",
       "...                  ...                ...                ...   \n",
       "42696              27.42              26.74              28.04   \n",
       "42697              27.46              26.86              28.00   \n",
       "42698              27.48              27.00              28.13   \n",
       "42699              27.58              26.98              28.06   \n",
       "42700              27.86              27.19              28.74   \n",
       "\n",
       "       Temp @ 60cm (C) Avg  Temp @ 60cm (C) Min  Temp @ 60cm (C) Max  \\\n",
       "0                    22.98                19.53                28.53   \n",
       "1                    22.06                18.97                25.60   \n",
       "2                    15.99                 6.22                21.15   \n",
       "3                     8.89                 2.67                17.87   \n",
       "4                     9.50                 1.66                19.85   \n",
       "...                    ...                  ...                  ...   \n",
       "42696                25.79                21.53                33.12   \n",
       "42697                26.29                22.82                33.19   \n",
       "42698                26.13                23.75                31.76   \n",
       "42699                26.16                22.78                31.11   \n",
       "42700                27.13                24.11                34.34   \n",
       "\n",
       "       Temp @ 2m (C) Avg  Temp @ 2m (C) Min  Temp @ 2m (C) Max  \\\n",
       "0                  23.24              19.87              28.18   \n",
       "1                  22.38              19.62              25.55   \n",
       "2                  16.26               7.12              21.46   \n",
       "3                   9.17               3.49              17.23   \n",
       "4                  10.01               2.51              19.30   \n",
       "...                  ...                ...                ...   \n",
       "42696              25.72              22.05              32.02   \n",
       "42697              26.34              23.33              32.45   \n",
       "42698              26.10              23.86              30.76   \n",
       "42699              26.35              23.86              30.38   \n",
       "42700              27.00              24.23              32.76   \n",
       "\n",
       "       Temp @ 10m (C) Avg  ...  Relative Humidity (%) Avg  \\\n",
       "0                   22.82  ...                      82.11   \n",
       "1                   22.01  ...                      87.47   \n",
       "2                   16.30  ...                      83.23   \n",
       "3                    9.38  ...                      76.71   \n",
       "4                   10.52  ...                      77.26   \n",
       "...                   ...  ...                        ...   \n",
       "42696               25.68  ...                      91.77   \n",
       "42697               26.37  ...                      92.80   \n",
       "42698               26.11  ...                      92.22   \n",
       "42699               26.32  ...                      93.90   \n",
       "42700               26.86  ...                      90.77   \n",
       "\n",
       "       Dew Point Temp (C) Avg  Dew Point Temp (C) Min  Dew Point Temp (C) Max  \\\n",
       "0                       19.81                   19.08                   21.31   \n",
       "1                       20.14                   18.60                   21.22   \n",
       "2                       13.10                    6.31                   20.18   \n",
       "3                        4.51                    2.86                    7.24   \n",
       "4                        5.50                    2.13                   12.36   \n",
       "...                       ...                     ...                     ...   \n",
       "42696                   24.16                   21.67                   26.63   \n",
       "42697                   25.02                   22.75                   28.01   \n",
       "42698                   24.67                   23.56                   26.92   \n",
       "42699                   25.24                   23.64                   28.00   \n",
       "42700                   25.19                   23.40                   27.67   \n",
       "\n",
       "       Wind Speed (mph) Avg  Wind Speed (mph) Max  Wind Direction (deg) Avg  \\\n",
       "0                      7.43                 13.50                    187.08   \n",
       "1                      7.30                 11.64                    206.36   \n",
       "2                      5.23                  9.81                    278.66   \n",
       "3                      2.87                  8.26                    250.10   \n",
       "4                      4.50                 15.19                    278.38   \n",
       "...                     ...                   ...                       ...   \n",
       "42696                  4.90                 12.30                    100.05   \n",
       "42697                  4.43                 15.28                    120.70   \n",
       "42698                  3.50                  8.22                    160.35   \n",
       "42699                  2.55                  7.01                    171.48   \n",
       "42700                  2.96                  9.81                    169.83   \n",
       "\n",
       "       Solar Radiation (w/m2) Avg  Solar Radiation (MJ/m2) Sum  \\\n",
       "0                          102.84                     8.885520   \n",
       "1                           56.00                     4.838430   \n",
       "2                          112.29                     9.701800   \n",
       "3                          146.77                    12.680800   \n",
       "4                          129.59                    11.196400   \n",
       "...                           ...                          ...   \n",
       "42696                      155.86                    13.325607   \n",
       "42697                      126.60                    10.938411   \n",
       "42698                      131.80                    11.387943   \n",
       "42699                      118.18                    10.210941   \n",
       "42700                      186.88                    16.146135   \n",
       "\n",
       "       ETo Grass (mm) Avg  \n",
       "0                    1.76  \n",
       "1                    1.38  \n",
       "2                    1.36  \n",
       "3                    1.06  \n",
       "4                    1.22  \n",
       "...                   ...  \n",
       "42696                3.02  \n",
       "42697                2.71  \n",
       "42698                2.66  \n",
       "42699                2.44  \n",
       "42700                3.49  \n",
       "\n",
       "[40437 rows x 22 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9a0504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6752390372568414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      7640\n",
      "           1       0.65      0.44      0.53      3977\n",
      "           2       0.69      0.06      0.11       515\n",
      "\n",
      "   micro avg       0.77      0.68      0.72     12132\n",
      "   macro avg       0.72      0.45      0.49     12132\n",
      "weighted avg       0.76      0.68      0.70     12132\n",
      " samples avg       0.68      0.68      0.68     12132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# KNN + Normal Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    " \n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "378cc9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6545499505440159\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80      6372\n",
      "           1       0.30      0.48      0.37      1347\n",
      "           2       0.16      0.38      0.23       369\n",
      "\n",
      "   micro avg       0.67      0.65      0.66      8088\n",
      "   macro avg       0.46      0.52      0.47      8088\n",
      "weighted avg       0.78      0.65      0.70      8088\n",
      " samples avg       0.65      0.65      0.65      8088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# KNN + SMOTE + RandomUnderSampler \n",
    "X_np = X.to_numpy()\n",
    "y_encoded_np = y_encoded.to_numpy()\n",
    "X_reshaped = X_np.reshape(-1, 22)\n",
    "y_reshaped = y_encoded_np.reshape(-1, 3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.2, random_state=42, stratify=y_reshaped)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('oversampling', SMOTE(random_state=42)),\n",
    "    ('undersampling', RandomUnderSampler(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2170ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6795252225519288\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      5073\n",
      "           1       0.54      0.53      0.54      2673\n",
      "           2       0.23      0.27      0.25       342\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      8088\n",
      "   macro avg       0.52      0.53      0.52      8088\n",
      "weighted avg       0.68      0.68      0.68      8088\n",
      " samples avg       0.68      0.68      0.68      8088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Decision Tree + Normal Data\n",
    "X = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35769e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7516073194856577\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      5073\n",
      "           1       0.70      0.58      0.64      2673\n",
      "           2       0.75      0.10      0.17       342\n",
      "\n",
      "   micro avg       0.79      0.75      0.77      8088\n",
      "   macro avg       0.76      0.52      0.56      8088\n",
      "weighted avg       0.79      0.75      0.76      8088\n",
      " samples avg       0.75      0.75      0.75      8088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Random Forest + Normal Data -> Promising results\n",
    "X = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3518ab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40437, 22)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cc1f782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40437, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1628705",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dbn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdbn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupervisedDBNClassification\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dbn'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671858fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones', 'Solar Radiation (MJ/m2) Sum', 'Wind Direction (deg) Avg',\n",
    "                                'ETo Grass (mm) Avg', 'Soil Temp (C) Avg'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e6ceb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Relative Humidity (%) Avg: 0.1341219121329885\n",
      "Feature Solar Radiation (w/m2) Avg: 0.09986320969529097\n",
      "Feature Wind Speed (mph) Max: 0.07142596299433619\n",
      "Feature Dew Point Temp (C) Max: 0.06416149324300434\n",
      "Feature Dew Point Temp (C) Min: 0.052197806084719515\n",
      "Feature Temp @ 60cm (C) Min: 0.05217203372806191\n",
      "Feature Soil Temp (C) Min: 0.04877560552835999\n",
      "Feature Soil Temp (C) Max: 0.04779998295404712\n",
      "Feature Temp @ 60cm (C) Max: 0.046961112227920716\n",
      "Feature Temp @ 10m (C) Min: 0.04597492427964966\n",
      "Feature Wind Speed (mph) Avg: 0.045857246887725474\n",
      "Feature Dew Point Temp (C) Avg: 0.045487765218100135\n",
      "Feature Temp @ 10m (C) Max: 0.04357619110617655\n",
      "Feature Temp @ 2m (C) Max: 0.04242638054775218\n",
      "Feature Temp @ 2m (C) Min: 0.04163205327776922\n",
      "Feature Temp @ 2m (C) Avg: 0.03970310557293742\n",
      "Feature Temp @ 60cm (C) Avg: 0.03938453261644333\n",
      "Feature Temp @ 10m (C) Avg: 0.03847868190471666\n"
     ]
    }
   ],
   "source": [
    "# Showing the weight each feature has for RandomForestClassifier\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    " \n",
    "feature_names = X_reduced.columns\n",
    "\n",
    " \n",
    "sorted_idx = feature_importance.argsort()[::-1]\n",
    "\n",
    " \n",
    "for i in range(len(sorted_idx)):\n",
    "    print(f\"Feature {feature_names[sorted_idx[i]]}: {feature_importance[sorted_idx[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81981cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.0-py3-none-win_amd64.whl (99.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rober\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\rober\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf970ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7818166831519947\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      7622\n",
      "           1       0.68      0.64      0.66      3956\n",
      "           2       0.57      0.16      0.24       554\n",
      "\n",
      "    accuracy                           0.78     12132\n",
      "   macro avg       0.70      0.57      0.59     12132\n",
      "weighted avg       0.77      0.78      0.77     12132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# XGB + Normal Data\n",
    "X_np = X.to_numpy()\n",
    "y_encoded_np = y_encoded.to_numpy()\n",
    "\n",
    "\n",
    "X_reshaped = X_np.reshape(-1, 22)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded_np, test_size=0.3, random_state=42, stratify=y_encoded_np)\n",
    "\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    objective='multi:softmax',  \n",
    "    num_class=3,              \n",
    "    random_state=42)          \n",
    "\n",
    "clf.fit(X_train, np.argmax(y_train, axis=1))  \n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "report = classification_report(y_test_labels, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db627dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6745796241345203\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      5081\n",
      "           1       0.65      0.50      0.56      2638\n",
      "           2       0.38      0.37      0.38       369\n",
      "\n",
      "   micro avg       0.79      0.67      0.73      8088\n",
      "   macro avg       0.64      0.55      0.59      8088\n",
      "weighted avg       0.78      0.67      0.72      8088\n",
      " samples avg       0.67      0.67      0.67      8088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# RandomForest + SMOTE + RandomUnderSampler\n",
    "X_np = X.to_numpy()\n",
    "y_encoded_np = y_encoded.to_numpy()\n",
    "\n",
    "\n",
    "X_reshaped = X_np.reshape(-1, 22)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded_np, test_size=0.2, random_state=42, stratify=y_encoded_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resampling_pipeline = Pipeline([\n",
    "    ('oversample', SMOTE(random_state=42)),              # Oversampling with SMOTE\n",
    "    ('undersample', RandomUnderSampler(random_state=42))  # Undersampling with RandomUnderSampler\n",
    "])\n",
    "\n",
    "# Fit and transform the training data using the resampling pipeline\n",
    "X_resampled, y_resampled = resampling_pipeline.fit_resample(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbe18c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\AppData\\Local\\Temp\\ipykernel_8948\\4149922023.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data.skew().sort_values(ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rainfall Amount (in) Sum       26.049628\n",
       "Wind Speed (mph) Max            3.270177\n",
       "Wind Speed (mph) Avg            1.467519\n",
       "Wind Direction (deg) Avg        0.133901\n",
       "ETo Grass (mm) Avg              0.065837\n",
       "Solar Radiation (w/m2) Avg     -0.243588\n",
       "Solar Radiation (MJ/m2) Sum    -0.252665\n",
       "Soil Temp (C) Max              -0.392056\n",
       "Soil Temp (C) Avg              -0.617659\n",
       "Soil Temp (C) Min              -0.769518\n",
       "Temp @ 2m (C) Min              -0.930854\n",
       "Temp @ 60cm (C) Min            -0.931906\n",
       "Temp @ 10m (C) Min             -0.999021\n",
       "Temp @ 60cm (C) Avg            -1.042268\n",
       "Temp @ 60cm (C) Max            -1.068883\n",
       "Temp @ 2m (C) Avg              -1.069891\n",
       "Temp @ 10m (C) Max             -1.080656\n",
       "Relative Humidity (%) Avg      -1.082487\n",
       "Temp @ 10m (C) Avg             -1.083534\n",
       "Temp @ 2m (C) Max              -1.124639\n",
       "Dew Point Temp (C) Avg         -1.226296\n",
       "Dew Point Temp (C) Max         -1.295445\n",
       "Dew Point Temp (C) Min         -2.270755\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7250ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.0 in c:\\users\\17866\\anaconda3\\lib\\site-packages (3.20.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f3db252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bcd6442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikeras) (0.30.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.4)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\17866\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf2fd102",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter activation for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(activation=relu)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m make_scorer(accuracy_score), cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Fit the grid search to your data\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Print the best parameters and results\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_result\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_result\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:668\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    666\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 668\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcloned_parameters)\n\u001b[0;32m    670\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    672\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:1165\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{param: value})\n\u001b[0;32m   1162\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1163\u001b[0m             \u001b[38;5;66;03m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;66;03m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[1;32m-> 1165\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1166\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1168\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1169\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheck the list of available parameters with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1171\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `estimator.get_params().keys()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1172\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter activation for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(activation=relu)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Define a function to create your neural network model\n",
    "def create_model(optimizer='adam', activation='relu', dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=22, activation=activation))\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier for use in GridSearchCV\n",
    "model = KerasClassifier(model=create_model, epochs = 20, batch_size = 32)\n",
    "\n",
    "# Define the hyperparameters and their possible values for the grid search\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'dropout_rate': [0.0, 0.2, 0.4]\n",
    "}\n",
    " \n",
    "    \n",
    "# Create the grid search object with your model and hyperparameter grid\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring= make_scorer(accuracy_score), cv=3)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and results\n",
    "print(f\"Best Accuracy: {grid_result.best_score_:.4f} using {grid_result.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18c818fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1138/1138 [==============================] - 6s 4ms/step - loss: 0.6592 - accuracy: 0.7065 - val_loss: 0.5911 - val_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.6009 - accuracy: 0.7424 - val_loss: 0.5752 - val_accuracy: 0.7542 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5876 - accuracy: 0.7469 - val_loss: 0.5584 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5777 - accuracy: 0.7501 - val_loss: 0.5545 - val_accuracy: 0.7641 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5723 - accuracy: 0.7538 - val_loss: 0.5482 - val_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5695 - accuracy: 0.7544 - val_loss: 0.5438 - val_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5646 - accuracy: 0.7580 - val_loss: 0.5381 - val_accuracy: 0.7695 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5623 - accuracy: 0.7611 - val_loss: 0.5385 - val_accuracy: 0.7715 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5614 - accuracy: 0.7595 - val_loss: 0.5339 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5578 - accuracy: 0.7613 - val_loss: 0.5329 - val_accuracy: 0.7740 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5559 - accuracy: 0.7620 - val_loss: 0.5316 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5543 - accuracy: 0.7633 - val_loss: 0.5317 - val_accuracy: 0.7755 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5559 - accuracy: 0.7626 - val_loss: 0.5316 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5548 - accuracy: 0.7620 - val_loss: 0.5312 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5540 - accuracy: 0.7614 - val_loss: 0.5311 - val_accuracy: 0.7760 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5544 - accuracy: 0.7623 - val_loss: 0.5310 - val_accuracy: 0.7755 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5531 - accuracy: 0.7646 - val_loss: 0.5312 - val_accuracy: 0.7760 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5528 - accuracy: 0.7642 - val_loss: 0.5304 - val_accuracy: 0.7755 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5528 - accuracy: 0.7640 - val_loss: 0.5300 - val_accuracy: 0.7760 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5516 - accuracy: 0.7636 - val_loss: 0.5297 - val_accuracy: 0.7765 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5525 - accuracy: 0.7630 - val_loss: 0.5303 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5531 - accuracy: 0.7626 - val_loss: 0.5305 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5527 - accuracy: 0.7637 - val_loss: 0.5299 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5519 - accuracy: 0.7633 - val_loss: 0.5295 - val_accuracy: 0.7760 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5522 - accuracy: 0.7642 - val_loss: 0.5292 - val_accuracy: 0.7779 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5527 - accuracy: 0.7644 - val_loss: 0.5292 - val_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5529 - accuracy: 0.7634 - val_loss: 0.5292 - val_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5512 - accuracy: 0.7639 - val_loss: 0.5290 - val_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5521 - accuracy: 0.7644 - val_loss: 0.5286 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5522 - accuracy: 0.7614 - val_loss: 0.5294 - val_accuracy: 0.7779 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5513 - accuracy: 0.7645 - val_loss: 0.5288 - val_accuracy: 0.7779 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5517 - accuracy: 0.7623 - val_loss: 0.5286 - val_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5527 - accuracy: 0.7634 - val_loss: 0.5289 - val_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5518 - accuracy: 0.7630 - val_loss: 0.5286 - val_accuracy: 0.7779 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5510 - accuracy: 0.7653 - val_loss: 0.5282 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5499 - accuracy: 0.7649 - val_loss: 0.5278 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5510 - accuracy: 0.7633 - val_loss: 0.5279 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5494 - accuracy: 0.7654 - val_loss: 0.5274 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5514 - accuracy: 0.7640 - val_loss: 0.5275 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5490 - accuracy: 0.7653 - val_loss: 0.5272 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5504 - accuracy: 0.7651 - val_loss: 0.5270 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5513 - accuracy: 0.7648 - val_loss: 0.5266 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5484 - accuracy: 0.7631 - val_loss: 0.5265 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5500 - accuracy: 0.7640 - val_loss: 0.5262 - val_accuracy: 0.7809 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5502 - accuracy: 0.7643 - val_loss: 0.5267 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5510 - accuracy: 0.7625 - val_loss: 0.5265 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5500 - accuracy: 0.7630 - val_loss: 0.5266 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5497 - accuracy: 0.7635 - val_loss: 0.5259 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5496 - accuracy: 0.7646 - val_loss: 0.5262 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5502 - accuracy: 0.7649 - val_loss: 0.5265 - val_accuracy: 0.7779 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5497 - accuracy: 0.7636 - val_loss: 0.5261 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5496 - accuracy: 0.7642 - val_loss: 0.5260 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5482 - accuracy: 0.7673 - val_loss: 0.5262 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5480 - accuracy: 0.7659 - val_loss: 0.5259 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5488 - accuracy: 0.7667 - val_loss: 0.5259 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5465 - accuracy: 0.7671 - val_loss: 0.5254 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5486 - accuracy: 0.7632 - val_loss: 0.5253 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5485 - accuracy: 0.7646 - val_loss: 0.5252 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5473 - accuracy: 0.7667 - val_loss: 0.5250 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5485 - accuracy: 0.7629 - val_loss: 0.5251 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5475 - accuracy: 0.7668 - val_loss: 0.5250 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5481 - accuracy: 0.7648 - val_loss: 0.5250 - val_accuracy: 0.7809 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5473 - accuracy: 0.7667 - val_loss: 0.5249 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5473 - accuracy: 0.7672 - val_loss: 0.5247 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5478 - accuracy: 0.7653 - val_loss: 0.5245 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5476 - accuracy: 0.7651 - val_loss: 0.5243 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5473 - accuracy: 0.7663 - val_loss: 0.5246 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5472 - accuracy: 0.7663 - val_loss: 0.5244 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5471 - accuracy: 0.7675 - val_loss: 0.5243 - val_accuracy: 0.7809 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5458 - accuracy: 0.7670 - val_loss: 0.5239 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5487 - accuracy: 0.7650 - val_loss: 0.5241 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5463 - accuracy: 0.7654 - val_loss: 0.5237 - val_accuracy: 0.7809 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5471 - accuracy: 0.7652 - val_loss: 0.5237 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5480 - accuracy: 0.7654 - val_loss: 0.5240 - val_accuracy: 0.7829 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5477 - accuracy: 0.7665 - val_loss: 0.5240 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5464 - accuracy: 0.7672 - val_loss: 0.5237 - val_accuracy: 0.7809 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5469 - accuracy: 0.7664 - val_loss: 0.5236 - val_accuracy: 0.7809 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5464 - accuracy: 0.7654 - val_loss: 0.5234 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "1138/1138 [==============================] - 3s 3ms/step - loss: 0.5465 - accuracy: 0.7656 - val_loss: 0.5232 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5462 - accuracy: 0.7672 - val_loss: 0.5231 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "1138/1138 [==============================] - 549s 483ms/step - loss: 0.5466 - accuracy: 0.7656 - val_loss: 0.5233 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "1138/1138 [==============================] - 8s 7ms/step - loss: 0.5467 - accuracy: 0.7661 - val_loss: 0.5234 - val_accuracy: 0.7834 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "1138/1138 [==============================] - 6s 5ms/step - loss: 0.5466 - accuracy: 0.7678 - val_loss: 0.5229 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "1138/1138 [==============================] - 5s 4ms/step - loss: 0.5469 - accuracy: 0.7654 - val_loss: 0.5227 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5454 - accuracy: 0.7663 - val_loss: 0.5228 - val_accuracy: 0.7799 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5480 - accuracy: 0.7651 - val_loss: 0.5227 - val_accuracy: 0.7834 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5460 - accuracy: 0.7658 - val_loss: 0.5236 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5470 - accuracy: 0.7652 - val_loss: 0.5231 - val_accuracy: 0.7834 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5459 - accuracy: 0.7674 - val_loss: 0.5230 - val_accuracy: 0.7844 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5461 - accuracy: 0.7659 - val_loss: 0.5226 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5455 - accuracy: 0.7679 - val_loss: 0.5230 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5442 - accuracy: 0.7673 - val_loss: 0.5222 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5443 - accuracy: 0.7670 - val_loss: 0.5223 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5443 - accuracy: 0.7682 - val_loss: 0.5220 - val_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5458 - accuracy: 0.7673 - val_loss: 0.5218 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5446 - accuracy: 0.7671 - val_loss: 0.5217 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5446 - accuracy: 0.7672 - val_loss: 0.5218 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5448 - accuracy: 0.7679 - val_loss: 0.5216 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1138/1138 [==============================] - 4s 3ms/step - loss: 0.5435 - accuracy: 0.7663 - val_loss: 0.5216 - val_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "1138/1138 [==============================] - 4s 4ms/step - loss: 0.5445 - accuracy: 0.7676 - val_loss: 0.5215 - val_accuracy: 0.7804 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7864\n",
      "Test loss: 0.5048\n",
      "Test accuracy: 0.7864\n",
      "64/64 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sequential FeedForward + Normal Data + Scaled + Early Stopping -> Best model\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(X_train_normalized.shape[1],)))\n",
    "#model.add(BatchNormalization())  # Add Batch Normalization for stability\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_normalized, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val_normalized, y_val), callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_normalized, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22b3dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2143/2143 [==============================] - 11s 4ms/step - loss: 0.8437 - accuracy: 0.5957 - val_loss: 0.6825 - val_accuracy: 0.6958 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.7645 - accuracy: 0.6439 - val_loss: 0.6487 - val_accuracy: 0.6944 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.7368 - accuracy: 0.6565 - val_loss: 1.2435 - val_accuracy: 0.3961 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "2143/2143 [==============================] - 8s 4ms/step - loss: 0.7170 - accuracy: 0.6658 - val_loss: 0.6707 - val_accuracy: 0.6815 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "2143/2143 [==============================] - 9s 4ms/step - loss: 0.7103 - accuracy: 0.6681 - val_loss: 0.5945 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 6/100\n",
      " 409/2143 [====>.........................] - ETA: 7s - loss: 0.7038 - accuracy: 0.6744"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 57>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m LearningRateScheduler(lr_scheduler)\n\u001b[0;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 57\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1654\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1655\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1656\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    328\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    349\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    393\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 394\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1094\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1171\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m     logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1171\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:297\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m         info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[1;32m--> 297\u001b[0m     \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(message)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py:460\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03msend will happen in the background thread\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mthread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# request flush on the background thread\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# waiting across threads during import can cause deadlocks\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# so only wait if import lock is not held\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m import_lock_held():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py:213\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mschedule\u001b[39m(\u001b[38;5;28mself\u001b[39m, f):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a function to be called in our IO thread.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    If the thread is not running, call immediately.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_alive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:1137\u001b[0m, in \u001b[0;36mThread.is_alive\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:1075\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1074\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m-> 1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39mlocked():\n\u001b[0;32m   1078\u001b[0m         \u001b[38;5;66;03m# bpo-45274: lock.acquire() acquired the lock, but the function\u001b[39;00m\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;66;03m# was interrupted with an exception before reaching the\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# lock.release(). It can happen if a signal handler raises an\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m         \u001b[38;5;66;03m# exception, like CTRL+C which raises KeyboardInterrupt.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Sequential FeedForward + SMOTE + RandomUnderSampler\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "pipeline = Pipeline([\n",
    "    ('oversampling', SMOTE(random_state=42)),\n",
    "    ('undersampling', RandomUnderSampler(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train.values)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(X_train_resampled.shape[1],)))\n",
    "model.add(BatchNormalization())  \n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(y_train_resampled.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# lower learning rate when epoch > 10\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da7ac681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7425816023738873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# RBM to extract features from dataset -> fed to RandomForest\n",
    "# Normal data\n",
    "rbm = BernoulliRBM(n_components=256, learning_rate=0.1, n_iter=10)\n",
    "rbm.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_features = rbm.transform(X_train)\n",
    "X_test_features = rbm.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_combined = np.concatenate((X_train, X_train_features), axis=1)\n",
    "X_test_combined = np.concatenate((X_test, X_test_features), axis=1)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "\n",
    "accuracy = clf.score(X_test_combined, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b27b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 3s 4ms/step - loss: 0.8679 - accuracy: 0.6716 - val_loss: 0.6473 - val_accuracy: 0.7289 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6874 - accuracy: 0.7122 - val_loss: 0.6848 - val_accuracy: 0.6737 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6568 - accuracy: 0.7147 - val_loss: 0.6281 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6314 - accuracy: 0.7305 - val_loss: 0.5929 - val_accuracy: 0.7444 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6158 - accuracy: 0.7362 - val_loss: 0.6145 - val_accuracy: 0.7276 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6042 - accuracy: 0.7423 - val_loss: 0.5854 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6055 - accuracy: 0.7393 - val_loss: 0.6458 - val_accuracy: 0.7045 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5886 - accuracy: 0.7458 - val_loss: 0.5681 - val_accuracy: 0.7584 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5770 - accuracy: 0.7538 - val_loss: 0.5846 - val_accuracy: 0.7602 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5768 - accuracy: 0.7552 - val_loss: 0.6021 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7698 - val_loss: 0.5588 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7701 - val_loss: 0.5656 - val_accuracy: 0.7559 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7712 - val_loss: 0.5582 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5589 - val_accuracy: 0.7610 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7696 - val_loss: 0.5544 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5390 - accuracy: 0.7703 - val_loss: 0.5563 - val_accuracy: 0.7642 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5390 - accuracy: 0.7716 - val_loss: 0.5491 - val_accuracy: 0.7711 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7721 - val_loss: 0.5472 - val_accuracy: 0.7706 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7699 - val_loss: 0.5475 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5366 - accuracy: 0.7724 - val_loss: 0.5500 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7728 - val_loss: 0.5482 - val_accuracy: 0.7724 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7716 - val_loss: 0.5445 - val_accuracy: 0.7739 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5358 - accuracy: 0.7718 - val_loss: 0.5441 - val_accuracy: 0.7746 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7725 - val_loss: 0.5528 - val_accuracy: 0.7686 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5354 - accuracy: 0.7728 - val_loss: 0.5445 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5336 - accuracy: 0.7739 - val_loss: 0.5453 - val_accuracy: 0.7728 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5332 - accuracy: 0.7743 - val_loss: 0.5476 - val_accuracy: 0.7719 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5335 - accuracy: 0.7735 - val_loss: 0.5417 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5317 - accuracy: 0.7744 - val_loss: 0.5436 - val_accuracy: 0.7720 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7741 - val_loss: 0.5443 - val_accuracy: 0.7734 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5300 - accuracy: 0.7747 - val_loss: 0.5443 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7731 - val_loss: 0.5463 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5305 - accuracy: 0.7737 - val_loss: 0.5404 - val_accuracy: 0.7751 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5299 - accuracy: 0.7732 - val_loss: 0.5527 - val_accuracy: 0.7674 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5294 - accuracy: 0.7758 - val_loss: 0.5417 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5297 - accuracy: 0.7767 - val_loss: 0.5402 - val_accuracy: 0.7766 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5281 - accuracy: 0.7768 - val_loss: 0.5479 - val_accuracy: 0.7696 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5279 - accuracy: 0.7750 - val_loss: 0.5382 - val_accuracy: 0.7773 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5281 - accuracy: 0.7746 - val_loss: 0.5404 - val_accuracy: 0.7741 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5287 - accuracy: 0.7746 - val_loss: 0.5417 - val_accuracy: 0.7736 - lr: 1.0000e-04\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7868\n",
      "Test loss: 0.5156\n",
      "Test accuracy: 0.7868\n",
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1D CNN, Normal data, early stopping to prevent overfitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "num_data_points, num_features = X_train.shape\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(num_data_points, num_features, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_features, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(num_features, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.5, callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb45538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1072/1072 [==============================] - 5s 3ms/step - loss: 0.5870 - accuracy: 0.7295 - val_loss: 11.6883 - val_accuracy: 0.2334 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.5144 - accuracy: 0.7577 - val_loss: 11.9106 - val_accuracy: 0.3173 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4887 - accuracy: 0.7719 - val_loss: 11.7683 - val_accuracy: 0.2720 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4706 - accuracy: 0.7792 - val_loss: 10.2868 - val_accuracy: 0.1245 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4667 - accuracy: 0.7850 - val_loss: 10.6427 - val_accuracy: 0.1261 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4541 - accuracy: 0.7907 - val_loss: 9.9193 - val_accuracy: 0.1153 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4564 - accuracy: 0.7903 - val_loss: 10.3077 - val_accuracy: 0.2834 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4493 - accuracy: 0.7947 - val_loss: 10.3678 - val_accuracy: 0.1589 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "1072/1072 [==============================] - 4s 3ms/step - loss: 0.4427 - accuracy: 0.7991 - val_loss: 11.8354 - val_accuracy: 0.2213 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4390 - accuracy: 0.8003 - val_loss: 12.2407 - val_accuracy: 0.2879 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4224 - accuracy: 0.8111 - val_loss: 12.8818 - val_accuracy: 0.2294 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "1072/1072 [==============================] - 4s 3ms/step - loss: 0.4193 - accuracy: 0.8135 - val_loss: 13.0040 - val_accuracy: 0.2126 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4185 - accuracy: 0.8130 - val_loss: 13.4460 - val_accuracy: 0.2261 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4174 - accuracy: 0.8138 - val_loss: 13.1118 - val_accuracy: 0.2259 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "1072/1072 [==============================] - 4s 4ms/step - loss: 0.4168 - accuracy: 0.8138 - val_loss: 13.0275 - val_accuracy: 0.2413 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "1072/1072 [==============================] - 4s 4ms/step - loss: 0.4168 - accuracy: 0.8139 - val_loss: 13.1071 - val_accuracy: 0.2028 - lr: 1.0000e-04\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 1.0250 - accuracy: 0.7238\n",
      "Test loss: 1.0250\n",
      "Test accuracy: 0.7238\n",
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN + SMOTE + RandomUnderSampler\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('oversampling', SMOTE(random_state=42)),\n",
    "    ('undersampling', RandomUnderSampler(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train.values)\n",
    "\n",
    "\n",
    "X_train_resampled = X_train_resampled.values\n",
    "X_test = X_test.values\n",
    "\n",
    "\n",
    "num_data_points, num_features = X_train_resampled.shape\n",
    "\n",
    "\n",
    "X_train_resampled = X_train_resampled.reshape(num_data_points, num_features, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_features, 1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(num_features, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=40, batch_size=32, validation_split=0.5, callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b4322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
