{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354bf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "\n",
    "def scraper(url):\n",
    "    stations = [\"Alachua_260\", \"Apopka_320\", \"Arcadia_490\", \"Avalon_304\", \"Babson Park_400\", \"Balm_350\", \"Belle Glade_410\", \"Bristol_190\", \"Bronson_230\", \n",
    "                \"Brooksville South_315\", \"Carrabelle_150\", \"Citra_250\", \"Clewiston_405\", \"Dade City_311\", \"DeFuniak Springs_120\", \"Dover\", \n",
    "                \"Fort Lauderdale_420\", \"Fort Pierce_430\", \"Hastings_270\", \"Homestead_440\", \"Immokalee_450\", \"Jay_110\", \"Joshua_241\", \"Kenansville_340\", \n",
    "                \"Lake Alfred_330\", \"Lecanto_275\", \"Live Oak_170\", \"Macclenny_180\", \"Marianna_130\", \"Mayo_121\", \"Monticello_160\",\"North Port_480\", \"Ocklawaha_280\",\n",
    "                \"Okahumpka_303\",\"Okeechobee_455\",\"Ona_380\",\"Palmdale_460\",\"Panama City_125\",\"Pierson_290\",\"Poinciana_335\",\"Putnam Hall_240\",\"Quincy_140\",\"Sebring_470\",\n",
    "                \"St. Lucie West_435\",\"Tiger Creek_395\",\"Umatilla_302\",\"Wellington_425\"]\n",
    "    \n",
    "    years = [\"2021.csv\", \"2022.csv\", \"2023.csv\"]\n",
    "    dataframe = []\n",
    "    for station in stations:\n",
    "        for year in years:\n",
    "            file_url = url + station + \"/\" + year\n",
    "            response = requests.get(file_url)\n",
    "            if response.status_code == 200:\n",
    "                df = pd.read_csv(io.StringIO(response.text))\n",
    "                dataframe.append(df)\n",
    "   \n",
    "                print(f\"merged: {station + year}\")\n",
    "            else:\n",
    "                print(f\"Failed to merge: {station + year}\")\n",
    "        \n",
    "         \n",
    "    final_df = pd.concat(dataframe, ignore_index=True)    \n",
    "    return final_df\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7632c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged: Alachua_2602021.csv\n",
      "merged: Alachua_2602022.csv\n",
      "merged: Alachua_2602023.csv\n",
      "merged: Apopka_3202021.csv\n",
      "merged: Apopka_3202022.csv\n",
      "merged: Apopka_3202023.csv\n",
      "merged: Arcadia_4902021.csv\n",
      "merged: Arcadia_4902022.csv\n",
      "merged: Arcadia_4902023.csv\n",
      "merged: Avalon_3042021.csv\n",
      "merged: Avalon_3042022.csv\n",
      "merged: Avalon_3042023.csv\n",
      "Failed to merge: Babson Park_4002021.csv\n",
      "merged: Babson Park_4002022.csv\n",
      "merged: Babson Park_4002023.csv\n",
      "merged: Balm_3502021.csv\n",
      "merged: Balm_3502022.csv\n",
      "merged: Balm_3502023.csv\n",
      "merged: Belle Glade_4102021.csv\n",
      "merged: Belle Glade_4102022.csv\n",
      "merged: Belle Glade_4102023.csv\n",
      "Failed to merge: Bristol_1902021.csv\n",
      "merged: Bristol_1902022.csv\n",
      "merged: Bristol_1902023.csv\n",
      "merged: Bronson_2302021.csv\n",
      "merged: Bronson_2302022.csv\n",
      "merged: Bronson_2302023.csv\n",
      "merged: Brooksville South_3152021.csv\n",
      "merged: Brooksville South_3152022.csv\n",
      "merged: Brooksville South_3152023.csv\n",
      "merged: Carrabelle_1502021.csv\n",
      "merged: Carrabelle_1502022.csv\n",
      "merged: Carrabelle_1502023.csv\n",
      "merged: Citra_2502021.csv\n",
      "merged: Citra_2502022.csv\n",
      "merged: Citra_2502023.csv\n",
      "merged: Clewiston_4052021.csv\n",
      "merged: Clewiston_4052022.csv\n",
      "merged: Clewiston_4052023.csv\n",
      "merged: Dade City_3112021.csv\n",
      "merged: Dade City_3112022.csv\n",
      "merged: Dade City_3112023.csv\n",
      "merged: DeFuniak Springs_1202021.csv\n",
      "merged: DeFuniak Springs_1202022.csv\n",
      "merged: DeFuniak Springs_1202023.csv\n",
      "Failed to merge: Dover2021.csv\n",
      "Failed to merge: Dover2022.csv\n",
      "Failed to merge: Dover2023.csv\n",
      "merged: Fort Lauderdale_4202021.csv\n",
      "merged: Fort Lauderdale_4202022.csv\n",
      "merged: Fort Lauderdale_4202023.csv\n",
      "merged: Fort Pierce_4302021.csv\n",
      "merged: Fort Pierce_4302022.csv\n",
      "merged: Fort Pierce_4302023.csv\n",
      "merged: Hastings_2702021.csv\n",
      "merged: Hastings_2702022.csv\n",
      "merged: Hastings_2702023.csv\n",
      "merged: Homestead_4402021.csv\n",
      "merged: Homestead_4402022.csv\n",
      "merged: Homestead_4402023.csv\n",
      "merged: Immokalee_4502021.csv\n",
      "merged: Immokalee_4502022.csv\n",
      "merged: Immokalee_4502023.csv\n",
      "merged: Jay_1102021.csv\n",
      "merged: Jay_1102022.csv\n",
      "merged: Jay_1102023.csv\n",
      "merged: Joshua_2412021.csv\n",
      "merged: Joshua_2412022.csv\n",
      "merged: Joshua_2412023.csv\n",
      "merged: Kenansville_3402021.csv\n",
      "merged: Kenansville_3402022.csv\n",
      "merged: Kenansville_3402023.csv\n",
      "merged: Lake Alfred_3302021.csv\n",
      "merged: Lake Alfred_3302022.csv\n",
      "merged: Lake Alfred_3302023.csv\n",
      "merged: Lecanto_2752021.csv\n",
      "merged: Lecanto_2752022.csv\n",
      "merged: Lecanto_2752023.csv\n",
      "merged: Live Oak_1702021.csv\n",
      "merged: Live Oak_1702022.csv\n",
      "merged: Live Oak_1702023.csv\n",
      "merged: Macclenny_1802021.csv\n",
      "merged: Macclenny_1802022.csv\n",
      "merged: Macclenny_1802023.csv\n",
      "merged: Marianna_1302021.csv\n",
      "merged: Marianna_1302022.csv\n",
      "merged: Marianna_1302023.csv\n",
      "merged: Mayo_1212021.csv\n",
      "merged: Mayo_1212022.csv\n",
      "merged: Mayo_1212023.csv\n",
      "merged: Monticello_1602021.csv\n",
      "merged: Monticello_1602022.csv\n",
      "merged: Monticello_1602023.csv\n",
      "merged: North Port_4802021.csv\n",
      "merged: North Port_4802022.csv\n",
      "merged: North Port_4802023.csv\n",
      "merged: Ocklawaha_2802021.csv\n",
      "merged: Ocklawaha_2802022.csv\n",
      "merged: Ocklawaha_2802023.csv\n",
      "merged: Okahumpka_3032021.csv\n",
      "merged: Okahumpka_3032022.csv\n",
      "merged: Okahumpka_3032023.csv\n",
      "merged: Okeechobee_4552021.csv\n",
      "merged: Okeechobee_4552022.csv\n",
      "merged: Okeechobee_4552023.csv\n",
      "merged: Ona_3802021.csv\n",
      "merged: Ona_3802022.csv\n",
      "merged: Ona_3802023.csv\n",
      "merged: Palmdale_4602021.csv\n",
      "merged: Palmdale_4602022.csv\n",
      "merged: Palmdale_4602023.csv\n",
      "Failed to merge: Panama City_1252021.csv\n",
      "merged: Panama City_1252022.csv\n",
      "merged: Panama City_1252023.csv\n",
      "merged: Pierson_2902021.csv\n",
      "merged: Pierson_2902022.csv\n",
      "merged: Pierson_2902023.csv\n",
      "Failed to merge: Poinciana_3352021.csv\n",
      "merged: Poinciana_3352022.csv\n",
      "merged: Poinciana_3352023.csv\n",
      "merged: Putnam Hall_2402021.csv\n",
      "merged: Putnam Hall_2402022.csv\n",
      "merged: Putnam Hall_2402023.csv\n",
      "merged: Quincy_1402021.csv\n",
      "merged: Quincy_1402022.csv\n",
      "merged: Quincy_1402023.csv\n",
      "merged: Sebring_4702021.csv\n",
      "merged: Sebring_4702022.csv\n",
      "merged: Sebring_4702023.csv\n",
      "merged: St. Lucie West_4352021.csv\n",
      "merged: St. Lucie West_4352022.csv\n",
      "merged: St. Lucie West_4352023.csv\n",
      "Failed to merge: Tiger Creek_3952021.csv\n",
      "merged: Tiger Creek_3952022.csv\n",
      "merged: Tiger Creek_3952023.csv\n",
      "merged: Umatilla_3022021.csv\n",
      "merged: Umatilla_3022022.csv\n",
      "merged: Umatilla_3022023.csv\n",
      "merged: Wellington_4252021.csv\n",
      "merged: Wellington_4252022.csv\n",
      "merged: Wellington_4252023.csv\n"
     ]
    }
   ],
   "source": [
    "data = scraper(\"https://fawn.ifas.ufl.edu/data/fawnpub/daily_summaries/BY_STATION/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcf7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=data.columns[-150:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24303811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['StationID', 'Date Time', 'Soil Temp (C) Avg', 'Soil Temp (C) Min',\n",
       "       'Soil Temp (C) Max', 'Temp @ 60cm (C) Avg', 'Temp @ 60cm (C) Min',\n",
       "       'Temp @ 60cm (C) Max', 'Temp @ 2m (C) Avg', 'Temp @ 2m (C) Min',\n",
       "       'Temp @ 2m (C) Max', 'Temp @ 10m (C) Avg', 'Temp @ 10m (C) Min',\n",
       "       'Temp @ 10m (C) Max', 'Relative Humidity (%) Avg',\n",
       "       'Dew Point Temp (C) Avg', 'Dew Point Temp (C) Min',\n",
       "       'Dew Point Temp (C) Max', 'Rainfall Amount (in) Sum',\n",
       "       'Wind Speed (mph) Avg', 'Wind Speed (mph) Max',\n",
       "       'Wind Direction (deg) Avg', 'Solar Radiation (w/m2) Avg',\n",
       "       'Solar Radiation (MJ/m2) Sum', 'ETo Grass (mm) Avg',\n",
       "       'Number of Observations'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9401e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns= [\"StationID\", \"Date Time\", \"Number of Observations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1cfddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc552d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rainfall -> 46.51\n",
      "Min Rainfall -> 0.0\n"
     ]
    }
   ],
   "source": [
    "# lets find the minimum and maximum values of rainfall in our dataset so that we can create a range\n",
    "min_rainfall = data['Rainfall Amount (in) Sum'].min()\n",
    "max_rainfall = data['Rainfall Amount (in) Sum'].max()\n",
    "print(f'Max Rainfall -> {max_rainfall}')\n",
    "print(f'Min Rainfall -> {min_rainfall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63559cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Temp (C) Avg</th>\n",
       "      <th>Soil Temp (C) Min</th>\n",
       "      <th>Soil Temp (C) Max</th>\n",
       "      <th>Temp @ 60cm (C) Avg</th>\n",
       "      <th>Temp @ 60cm (C) Min</th>\n",
       "      <th>Temp @ 60cm (C) Max</th>\n",
       "      <th>Temp @ 2m (C) Avg</th>\n",
       "      <th>Temp @ 2m (C) Min</th>\n",
       "      <th>Temp @ 2m (C) Max</th>\n",
       "      <th>Temp @ 10m (C) Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Dew Point Temp (C) Avg</th>\n",
       "      <th>Dew Point Temp (C) Min</th>\n",
       "      <th>Dew Point Temp (C) Max</th>\n",
       "      <th>Rainfall Amount (in) Sum</th>\n",
       "      <th>Wind Speed (mph) Avg</th>\n",
       "      <th>Wind Speed (mph) Max</th>\n",
       "      <th>Wind Direction (deg) Avg</th>\n",
       "      <th>Solar Radiation (w/m2) Avg</th>\n",
       "      <th>Solar Radiation (MJ/m2) Sum</th>\n",
       "      <th>ETo Grass (mm) Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.02</td>\n",
       "      <td>17.02</td>\n",
       "      <td>19.40</td>\n",
       "      <td>22.98</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.53</td>\n",
       "      <td>23.24</td>\n",
       "      <td>19.87</td>\n",
       "      <td>28.18</td>\n",
       "      <td>22.82</td>\n",
       "      <td>...</td>\n",
       "      <td>19.81</td>\n",
       "      <td>19.08</td>\n",
       "      <td>21.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.43</td>\n",
       "      <td>13.50</td>\n",
       "      <td>187.08</td>\n",
       "      <td>102.84</td>\n",
       "      <td>8.885520</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.56</td>\n",
       "      <td>17.86</td>\n",
       "      <td>19.32</td>\n",
       "      <td>22.06</td>\n",
       "      <td>18.97</td>\n",
       "      <td>25.60</td>\n",
       "      <td>22.38</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.55</td>\n",
       "      <td>22.01</td>\n",
       "      <td>...</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.60</td>\n",
       "      <td>21.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.30</td>\n",
       "      <td>11.64</td>\n",
       "      <td>206.36</td>\n",
       "      <td>56.00</td>\n",
       "      <td>4.838430</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.44</td>\n",
       "      <td>16.76</td>\n",
       "      <td>19.23</td>\n",
       "      <td>15.99</td>\n",
       "      <td>6.22</td>\n",
       "      <td>21.15</td>\n",
       "      <td>16.26</td>\n",
       "      <td>7.12</td>\n",
       "      <td>21.46</td>\n",
       "      <td>16.30</td>\n",
       "      <td>...</td>\n",
       "      <td>13.10</td>\n",
       "      <td>6.31</td>\n",
       "      <td>20.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.23</td>\n",
       "      <td>9.81</td>\n",
       "      <td>278.66</td>\n",
       "      <td>112.29</td>\n",
       "      <td>9.701800</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.42</td>\n",
       "      <td>13.96</td>\n",
       "      <td>16.74</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2.67</td>\n",
       "      <td>17.87</td>\n",
       "      <td>9.17</td>\n",
       "      <td>3.49</td>\n",
       "      <td>17.23</td>\n",
       "      <td>9.38</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.26</td>\n",
       "      <td>250.10</td>\n",
       "      <td>146.77</td>\n",
       "      <td>12.680800</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.09</td>\n",
       "      <td>12.54</td>\n",
       "      <td>15.71</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>19.85</td>\n",
       "      <td>10.01</td>\n",
       "      <td>2.51</td>\n",
       "      <td>19.30</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.50</td>\n",
       "      <td>15.19</td>\n",
       "      <td>278.38</td>\n",
       "      <td>129.59</td>\n",
       "      <td>11.196400</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>27.42</td>\n",
       "      <td>26.74</td>\n",
       "      <td>28.04</td>\n",
       "      <td>25.79</td>\n",
       "      <td>21.53</td>\n",
       "      <td>33.12</td>\n",
       "      <td>25.72</td>\n",
       "      <td>22.05</td>\n",
       "      <td>32.02</td>\n",
       "      <td>25.68</td>\n",
       "      <td>...</td>\n",
       "      <td>24.16</td>\n",
       "      <td>21.67</td>\n",
       "      <td>26.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.90</td>\n",
       "      <td>12.30</td>\n",
       "      <td>100.05</td>\n",
       "      <td>155.86</td>\n",
       "      <td>13.325607</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42697</th>\n",
       "      <td>27.46</td>\n",
       "      <td>26.86</td>\n",
       "      <td>28.00</td>\n",
       "      <td>26.29</td>\n",
       "      <td>22.82</td>\n",
       "      <td>33.19</td>\n",
       "      <td>26.34</td>\n",
       "      <td>23.33</td>\n",
       "      <td>32.45</td>\n",
       "      <td>26.37</td>\n",
       "      <td>...</td>\n",
       "      <td>25.02</td>\n",
       "      <td>22.75</td>\n",
       "      <td>28.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.43</td>\n",
       "      <td>15.28</td>\n",
       "      <td>120.70</td>\n",
       "      <td>126.60</td>\n",
       "      <td>10.938411</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42698</th>\n",
       "      <td>27.48</td>\n",
       "      <td>27.00</td>\n",
       "      <td>28.13</td>\n",
       "      <td>26.13</td>\n",
       "      <td>23.75</td>\n",
       "      <td>31.76</td>\n",
       "      <td>26.10</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.76</td>\n",
       "      <td>26.11</td>\n",
       "      <td>...</td>\n",
       "      <td>24.67</td>\n",
       "      <td>23.56</td>\n",
       "      <td>26.92</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.50</td>\n",
       "      <td>8.22</td>\n",
       "      <td>160.35</td>\n",
       "      <td>131.80</td>\n",
       "      <td>11.387943</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>27.58</td>\n",
       "      <td>26.98</td>\n",
       "      <td>28.06</td>\n",
       "      <td>26.16</td>\n",
       "      <td>22.78</td>\n",
       "      <td>31.11</td>\n",
       "      <td>26.35</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.38</td>\n",
       "      <td>26.32</td>\n",
       "      <td>...</td>\n",
       "      <td>25.24</td>\n",
       "      <td>23.64</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.01</td>\n",
       "      <td>171.48</td>\n",
       "      <td>118.18</td>\n",
       "      <td>10.210941</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42700</th>\n",
       "      <td>27.86</td>\n",
       "      <td>27.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>27.13</td>\n",
       "      <td>24.11</td>\n",
       "      <td>34.34</td>\n",
       "      <td>27.00</td>\n",
       "      <td>24.23</td>\n",
       "      <td>32.76</td>\n",
       "      <td>26.86</td>\n",
       "      <td>...</td>\n",
       "      <td>25.19</td>\n",
       "      <td>23.40</td>\n",
       "      <td>27.67</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.96</td>\n",
       "      <td>9.81</td>\n",
       "      <td>169.83</td>\n",
       "      <td>186.88</td>\n",
       "      <td>16.146135</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40437 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Soil Temp (C) Avg  Soil Temp (C) Min  Soil Temp (C) Max  \\\n",
       "0                  18.02              17.02              19.40   \n",
       "1                  18.56              17.86              19.32   \n",
       "2                  18.44              16.76              19.23   \n",
       "3                  15.42              13.96              16.74   \n",
       "4                  14.09              12.54              15.71   \n",
       "...                  ...                ...                ...   \n",
       "42696              27.42              26.74              28.04   \n",
       "42697              27.46              26.86              28.00   \n",
       "42698              27.48              27.00              28.13   \n",
       "42699              27.58              26.98              28.06   \n",
       "42700              27.86              27.19              28.74   \n",
       "\n",
       "       Temp @ 60cm (C) Avg  Temp @ 60cm (C) Min  Temp @ 60cm (C) Max  \\\n",
       "0                    22.98                19.53                28.53   \n",
       "1                    22.06                18.97                25.60   \n",
       "2                    15.99                 6.22                21.15   \n",
       "3                     8.89                 2.67                17.87   \n",
       "4                     9.50                 1.66                19.85   \n",
       "...                    ...                  ...                  ...   \n",
       "42696                25.79                21.53                33.12   \n",
       "42697                26.29                22.82                33.19   \n",
       "42698                26.13                23.75                31.76   \n",
       "42699                26.16                22.78                31.11   \n",
       "42700                27.13                24.11                34.34   \n",
       "\n",
       "       Temp @ 2m (C) Avg  Temp @ 2m (C) Min  Temp @ 2m (C) Max  \\\n",
       "0                  23.24              19.87              28.18   \n",
       "1                  22.38              19.62              25.55   \n",
       "2                  16.26               7.12              21.46   \n",
       "3                   9.17               3.49              17.23   \n",
       "4                  10.01               2.51              19.30   \n",
       "...                  ...                ...                ...   \n",
       "42696              25.72              22.05              32.02   \n",
       "42697              26.34              23.33              32.45   \n",
       "42698              26.10              23.86              30.76   \n",
       "42699              26.35              23.86              30.38   \n",
       "42700              27.00              24.23              32.76   \n",
       "\n",
       "       Temp @ 10m (C) Avg  ...  Dew Point Temp (C) Avg  \\\n",
       "0                   22.82  ...                   19.81   \n",
       "1                   22.01  ...                   20.14   \n",
       "2                   16.30  ...                   13.10   \n",
       "3                    9.38  ...                    4.51   \n",
       "4                   10.52  ...                    5.50   \n",
       "...                   ...  ...                     ...   \n",
       "42696               25.68  ...                   24.16   \n",
       "42697               26.37  ...                   25.02   \n",
       "42698               26.11  ...                   24.67   \n",
       "42699               26.32  ...                   25.24   \n",
       "42700               26.86  ...                   25.19   \n",
       "\n",
       "       Dew Point Temp (C) Min  Dew Point Temp (C) Max  \\\n",
       "0                       19.08                   21.31   \n",
       "1                       18.60                   21.22   \n",
       "2                        6.31                   20.18   \n",
       "3                        2.86                    7.24   \n",
       "4                        2.13                   12.36   \n",
       "...                       ...                     ...   \n",
       "42696                   21.67                   26.63   \n",
       "42697                   22.75                   28.01   \n",
       "42698                   23.56                   26.92   \n",
       "42699                   23.64                   28.00   \n",
       "42700                   23.40                   27.67   \n",
       "\n",
       "       Rainfall Amount (in) Sum  Wind Speed (mph) Avg  Wind Speed (mph) Max  \\\n",
       "0                          0.00                  7.43                 13.50   \n",
       "1                          0.00                  7.30                 11.64   \n",
       "2                          0.41                  5.23                  9.81   \n",
       "3                          0.00                  2.87                  8.26   \n",
       "4                          0.05                  4.50                 15.19   \n",
       "...                         ...                   ...                   ...   \n",
       "42696                      1.14                  4.90                 12.30   \n",
       "42697                      0.46                  4.43                 15.28   \n",
       "42698                      0.11                  3.50                  8.22   \n",
       "42699                      0.01                  2.55                  7.01   \n",
       "42700                      0.17                  2.96                  9.81   \n",
       "\n",
       "       Wind Direction (deg) Avg  Solar Radiation (w/m2) Avg  \\\n",
       "0                        187.08                      102.84   \n",
       "1                        206.36                       56.00   \n",
       "2                        278.66                      112.29   \n",
       "3                        250.10                      146.77   \n",
       "4                        278.38                      129.59   \n",
       "...                         ...                         ...   \n",
       "42696                    100.05                      155.86   \n",
       "42697                    120.70                      126.60   \n",
       "42698                    160.35                      131.80   \n",
       "42699                    171.48                      118.18   \n",
       "42700                    169.83                      186.88   \n",
       "\n",
       "       Solar Radiation (MJ/m2) Sum  ETo Grass (mm) Avg  \n",
       "0                         8.885520                1.76  \n",
       "1                         4.838430                1.38  \n",
       "2                         9.701800                1.36  \n",
       "3                        12.680800                1.06  \n",
       "4                        11.196400                1.22  \n",
       "...                            ...                 ...  \n",
       "42696                    13.325607                3.02  \n",
       "42697                    10.938411                2.71  \n",
       "42698                    11.387943                2.66  \n",
       "42699                    10.210941                2.44  \n",
       "42700                    16.146135                3.49  \n",
       "\n",
       "[40437 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e374bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q1 = np.percentile(data['Rainfall Amount (in) Sum'], 25)\n",
    "median = np.percentile(data['Rainfall Amount (in) Sum'], 50)\n",
    "q3 = np.percentile(data['Rainfall Amount (in) Sum'], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98aa2455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1298b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-float(\"inf\"), 0.01, 1.0 , float('inf')]\n",
    "        \n",
    "\n",
    "# Define labels for the bins\n",
    "labels = ['0-0.01', '0.01-1.0',float(\"inf\")]\n",
    "\n",
    "# Use pd.cut() to create the intervals\n",
    "data = data.copy()\n",
    "data.loc[:, 'zones'] = pd.cut(data['Rainfall Amount (in) Sum'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3185534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40437.000000\n",
       "mean         0.151922\n",
       "std          0.522670\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.050000\n",
       "max         46.510000\n",
       "Name: Rainfall Amount (in) Sum, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rainfall Amount (in) Sum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf58a8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.boxplot(column='Rainfall Amount (in) Sum')\n",
    "plt.ylabel('Rainfall Amount (in) Sum')\n",
    "plt.title('Box Plot of Rainfall Amount (in) Sum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c34f46e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1847\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for v in data['Rainfall Amount (in) Sum']:\n",
    "    if v >= 1.0:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab807a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     40437\n",
       "unique        3\n",
       "top       0-0.2\n",
       "freq      33774\n",
       "Name: zones, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['zones'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5911dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = pd.get_dummies(data['zones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4dbb578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-0.01</th>\n",
       "      <th>0.01-1.0</th>\n",
       "      <th>inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42697</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42698</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42700</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40437 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0-0.01  0.01-1.0  inf\n",
       "0           1         0    0\n",
       "1           1         0    0\n",
       "2           0         1    0\n",
       "3           1         0    0\n",
       "4           0         1    0\n",
       "...       ...       ...  ...\n",
       "42696       0         0    1\n",
       "42697       0         1    0\n",
       "42698       0         1    0\n",
       "42699       0         1    0\n",
       "42700       0         1    0\n",
       "\n",
       "[40437 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e9a23de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38590\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for v in y_encoded[float(\"inf\")]:\n",
    "    if v == 0.0:\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cda3c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f220425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Temp (C) Avg</th>\n",
       "      <th>Soil Temp (C) Min</th>\n",
       "      <th>Soil Temp (C) Max</th>\n",
       "      <th>Temp @ 60cm (C) Avg</th>\n",
       "      <th>Temp @ 60cm (C) Min</th>\n",
       "      <th>Temp @ 60cm (C) Max</th>\n",
       "      <th>Temp @ 2m (C) Avg</th>\n",
       "      <th>Temp @ 2m (C) Min</th>\n",
       "      <th>Temp @ 2m (C) Max</th>\n",
       "      <th>Temp @ 10m (C) Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Relative Humidity (%) Avg</th>\n",
       "      <th>Dew Point Temp (C) Avg</th>\n",
       "      <th>Dew Point Temp (C) Min</th>\n",
       "      <th>Dew Point Temp (C) Max</th>\n",
       "      <th>Wind Speed (mph) Avg</th>\n",
       "      <th>Wind Speed (mph) Max</th>\n",
       "      <th>Wind Direction (deg) Avg</th>\n",
       "      <th>Solar Radiation (w/m2) Avg</th>\n",
       "      <th>Solar Radiation (MJ/m2) Sum</th>\n",
       "      <th>ETo Grass (mm) Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.02</td>\n",
       "      <td>17.02</td>\n",
       "      <td>19.40</td>\n",
       "      <td>22.98</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.53</td>\n",
       "      <td>23.24</td>\n",
       "      <td>19.87</td>\n",
       "      <td>28.18</td>\n",
       "      <td>22.82</td>\n",
       "      <td>...</td>\n",
       "      <td>82.11</td>\n",
       "      <td>19.81</td>\n",
       "      <td>19.08</td>\n",
       "      <td>21.31</td>\n",
       "      <td>7.43</td>\n",
       "      <td>13.50</td>\n",
       "      <td>187.08</td>\n",
       "      <td>102.84</td>\n",
       "      <td>8.885520</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.56</td>\n",
       "      <td>17.86</td>\n",
       "      <td>19.32</td>\n",
       "      <td>22.06</td>\n",
       "      <td>18.97</td>\n",
       "      <td>25.60</td>\n",
       "      <td>22.38</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.55</td>\n",
       "      <td>22.01</td>\n",
       "      <td>...</td>\n",
       "      <td>87.47</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.60</td>\n",
       "      <td>21.22</td>\n",
       "      <td>7.30</td>\n",
       "      <td>11.64</td>\n",
       "      <td>206.36</td>\n",
       "      <td>56.00</td>\n",
       "      <td>4.838430</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.44</td>\n",
       "      <td>16.76</td>\n",
       "      <td>19.23</td>\n",
       "      <td>15.99</td>\n",
       "      <td>6.22</td>\n",
       "      <td>21.15</td>\n",
       "      <td>16.26</td>\n",
       "      <td>7.12</td>\n",
       "      <td>21.46</td>\n",
       "      <td>16.30</td>\n",
       "      <td>...</td>\n",
       "      <td>83.23</td>\n",
       "      <td>13.10</td>\n",
       "      <td>6.31</td>\n",
       "      <td>20.18</td>\n",
       "      <td>5.23</td>\n",
       "      <td>9.81</td>\n",
       "      <td>278.66</td>\n",
       "      <td>112.29</td>\n",
       "      <td>9.701800</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.42</td>\n",
       "      <td>13.96</td>\n",
       "      <td>16.74</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2.67</td>\n",
       "      <td>17.87</td>\n",
       "      <td>9.17</td>\n",
       "      <td>3.49</td>\n",
       "      <td>17.23</td>\n",
       "      <td>9.38</td>\n",
       "      <td>...</td>\n",
       "      <td>76.71</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.24</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.26</td>\n",
       "      <td>250.10</td>\n",
       "      <td>146.77</td>\n",
       "      <td>12.680800</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.09</td>\n",
       "      <td>12.54</td>\n",
       "      <td>15.71</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>19.85</td>\n",
       "      <td>10.01</td>\n",
       "      <td>2.51</td>\n",
       "      <td>19.30</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>77.26</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12.36</td>\n",
       "      <td>4.50</td>\n",
       "      <td>15.19</td>\n",
       "      <td>278.38</td>\n",
       "      <td>129.59</td>\n",
       "      <td>11.196400</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>27.42</td>\n",
       "      <td>26.74</td>\n",
       "      <td>28.04</td>\n",
       "      <td>25.79</td>\n",
       "      <td>21.53</td>\n",
       "      <td>33.12</td>\n",
       "      <td>25.72</td>\n",
       "      <td>22.05</td>\n",
       "      <td>32.02</td>\n",
       "      <td>25.68</td>\n",
       "      <td>...</td>\n",
       "      <td>91.77</td>\n",
       "      <td>24.16</td>\n",
       "      <td>21.67</td>\n",
       "      <td>26.63</td>\n",
       "      <td>4.90</td>\n",
       "      <td>12.30</td>\n",
       "      <td>100.05</td>\n",
       "      <td>155.86</td>\n",
       "      <td>13.325607</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42697</th>\n",
       "      <td>27.46</td>\n",
       "      <td>26.86</td>\n",
       "      <td>28.00</td>\n",
       "      <td>26.29</td>\n",
       "      <td>22.82</td>\n",
       "      <td>33.19</td>\n",
       "      <td>26.34</td>\n",
       "      <td>23.33</td>\n",
       "      <td>32.45</td>\n",
       "      <td>26.37</td>\n",
       "      <td>...</td>\n",
       "      <td>92.80</td>\n",
       "      <td>25.02</td>\n",
       "      <td>22.75</td>\n",
       "      <td>28.01</td>\n",
       "      <td>4.43</td>\n",
       "      <td>15.28</td>\n",
       "      <td>120.70</td>\n",
       "      <td>126.60</td>\n",
       "      <td>10.938411</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42698</th>\n",
       "      <td>27.48</td>\n",
       "      <td>27.00</td>\n",
       "      <td>28.13</td>\n",
       "      <td>26.13</td>\n",
       "      <td>23.75</td>\n",
       "      <td>31.76</td>\n",
       "      <td>26.10</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.76</td>\n",
       "      <td>26.11</td>\n",
       "      <td>...</td>\n",
       "      <td>92.22</td>\n",
       "      <td>24.67</td>\n",
       "      <td>23.56</td>\n",
       "      <td>26.92</td>\n",
       "      <td>3.50</td>\n",
       "      <td>8.22</td>\n",
       "      <td>160.35</td>\n",
       "      <td>131.80</td>\n",
       "      <td>11.387943</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>27.58</td>\n",
       "      <td>26.98</td>\n",
       "      <td>28.06</td>\n",
       "      <td>26.16</td>\n",
       "      <td>22.78</td>\n",
       "      <td>31.11</td>\n",
       "      <td>26.35</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.38</td>\n",
       "      <td>26.32</td>\n",
       "      <td>...</td>\n",
       "      <td>93.90</td>\n",
       "      <td>25.24</td>\n",
       "      <td>23.64</td>\n",
       "      <td>28.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.01</td>\n",
       "      <td>171.48</td>\n",
       "      <td>118.18</td>\n",
       "      <td>10.210941</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42700</th>\n",
       "      <td>27.86</td>\n",
       "      <td>27.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>27.13</td>\n",
       "      <td>24.11</td>\n",
       "      <td>34.34</td>\n",
       "      <td>27.00</td>\n",
       "      <td>24.23</td>\n",
       "      <td>32.76</td>\n",
       "      <td>26.86</td>\n",
       "      <td>...</td>\n",
       "      <td>90.77</td>\n",
       "      <td>25.19</td>\n",
       "      <td>23.40</td>\n",
       "      <td>27.67</td>\n",
       "      <td>2.96</td>\n",
       "      <td>9.81</td>\n",
       "      <td>169.83</td>\n",
       "      <td>186.88</td>\n",
       "      <td>16.146135</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40437 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Soil Temp (C) Avg  Soil Temp (C) Min  Soil Temp (C) Max  \\\n",
       "0                  18.02              17.02              19.40   \n",
       "1                  18.56              17.86              19.32   \n",
       "2                  18.44              16.76              19.23   \n",
       "3                  15.42              13.96              16.74   \n",
       "4                  14.09              12.54              15.71   \n",
       "...                  ...                ...                ...   \n",
       "42696              27.42              26.74              28.04   \n",
       "42697              27.46              26.86              28.00   \n",
       "42698              27.48              27.00              28.13   \n",
       "42699              27.58              26.98              28.06   \n",
       "42700              27.86              27.19              28.74   \n",
       "\n",
       "       Temp @ 60cm (C) Avg  Temp @ 60cm (C) Min  Temp @ 60cm (C) Max  \\\n",
       "0                    22.98                19.53                28.53   \n",
       "1                    22.06                18.97                25.60   \n",
       "2                    15.99                 6.22                21.15   \n",
       "3                     8.89                 2.67                17.87   \n",
       "4                     9.50                 1.66                19.85   \n",
       "...                    ...                  ...                  ...   \n",
       "42696                25.79                21.53                33.12   \n",
       "42697                26.29                22.82                33.19   \n",
       "42698                26.13                23.75                31.76   \n",
       "42699                26.16                22.78                31.11   \n",
       "42700                27.13                24.11                34.34   \n",
       "\n",
       "       Temp @ 2m (C) Avg  Temp @ 2m (C) Min  Temp @ 2m (C) Max  \\\n",
       "0                  23.24              19.87              28.18   \n",
       "1                  22.38              19.62              25.55   \n",
       "2                  16.26               7.12              21.46   \n",
       "3                   9.17               3.49              17.23   \n",
       "4                  10.01               2.51              19.30   \n",
       "...                  ...                ...                ...   \n",
       "42696              25.72              22.05              32.02   \n",
       "42697              26.34              23.33              32.45   \n",
       "42698              26.10              23.86              30.76   \n",
       "42699              26.35              23.86              30.38   \n",
       "42700              27.00              24.23              32.76   \n",
       "\n",
       "       Temp @ 10m (C) Avg  ...  Relative Humidity (%) Avg  \\\n",
       "0                   22.82  ...                      82.11   \n",
       "1                   22.01  ...                      87.47   \n",
       "2                   16.30  ...                      83.23   \n",
       "3                    9.38  ...                      76.71   \n",
       "4                   10.52  ...                      77.26   \n",
       "...                   ...  ...                        ...   \n",
       "42696               25.68  ...                      91.77   \n",
       "42697               26.37  ...                      92.80   \n",
       "42698               26.11  ...                      92.22   \n",
       "42699               26.32  ...                      93.90   \n",
       "42700               26.86  ...                      90.77   \n",
       "\n",
       "       Dew Point Temp (C) Avg  Dew Point Temp (C) Min  Dew Point Temp (C) Max  \\\n",
       "0                       19.81                   19.08                   21.31   \n",
       "1                       20.14                   18.60                   21.22   \n",
       "2                       13.10                    6.31                   20.18   \n",
       "3                        4.51                    2.86                    7.24   \n",
       "4                        5.50                    2.13                   12.36   \n",
       "...                       ...                     ...                     ...   \n",
       "42696                   24.16                   21.67                   26.63   \n",
       "42697                   25.02                   22.75                   28.01   \n",
       "42698                   24.67                   23.56                   26.92   \n",
       "42699                   25.24                   23.64                   28.00   \n",
       "42700                   25.19                   23.40                   27.67   \n",
       "\n",
       "       Wind Speed (mph) Avg  Wind Speed (mph) Max  Wind Direction (deg) Avg  \\\n",
       "0                      7.43                 13.50                    187.08   \n",
       "1                      7.30                 11.64                    206.36   \n",
       "2                      5.23                  9.81                    278.66   \n",
       "3                      2.87                  8.26                    250.10   \n",
       "4                      4.50                 15.19                    278.38   \n",
       "...                     ...                   ...                       ...   \n",
       "42696                  4.90                 12.30                    100.05   \n",
       "42697                  4.43                 15.28                    120.70   \n",
       "42698                  3.50                  8.22                    160.35   \n",
       "42699                  2.55                  7.01                    171.48   \n",
       "42700                  2.96                  9.81                    169.83   \n",
       "\n",
       "       Solar Radiation (w/m2) Avg  Solar Radiation (MJ/m2) Sum  \\\n",
       "0                          102.84                     8.885520   \n",
       "1                           56.00                     4.838430   \n",
       "2                          112.29                     9.701800   \n",
       "3                          146.77                    12.680800   \n",
       "4                          129.59                    11.196400   \n",
       "...                           ...                          ...   \n",
       "42696                      155.86                    13.325607   \n",
       "42697                      126.60                    10.938411   \n",
       "42698                      131.80                    11.387943   \n",
       "42699                      118.18                    10.210941   \n",
       "42700                      186.88                    16.146135   \n",
       "\n",
       "       ETo Grass (mm) Avg  \n",
       "0                    1.76  \n",
       "1                    1.38  \n",
       "2                    1.36  \n",
       "3                    1.06  \n",
       "4                    1.22  \n",
       "...                   ...  \n",
       "42696                3.02  \n",
       "42697                2.71  \n",
       "42698                2.66  \n",
       "42699                2.44  \n",
       "42700                3.49  \n",
       "\n",
       "[40437 rows x 22 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6e9a0504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6752390372568414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      7640\n",
      "           1       0.65      0.44      0.53      3977\n",
      "           2       0.69      0.06      0.11       515\n",
      "\n",
      "   micro avg       0.77      0.68      0.72     12132\n",
      "   macro avg       0.72      0.45      0.49     12132\n",
      "weighted avg       0.76      0.68      0.70     12132\n",
      " samples avg       0.68      0.68      0.68     12132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# KNN + Normal Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    " \n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "378cc9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6545499505440159\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80      6372\n",
      "           1       0.30      0.48      0.37      1347\n",
      "           2       0.16      0.38      0.23       369\n",
      "\n",
      "   micro avg       0.67      0.65      0.66      8088\n",
      "   macro avg       0.46      0.52      0.47      8088\n",
      "weighted avg       0.78      0.65      0.70      8088\n",
      " samples avg       0.65      0.65      0.65      8088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# KNN + SMOTE + RandomUnderSampler \n",
    "X_np = X.to_numpy()\n",
    "y_encoded_np = y_encoded.to_numpy()\n",
    "X_reshaped = X_np.reshape(-1, 22)\n",
    "y_reshaped = y_encoded_np.reshape(-1, 3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.2, random_state=42, stratify=y_reshaped)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('oversampling', SMOTE(random_state=42)),\n",
    "    ('undersampling', RandomUnderSampler(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2170ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6795252225519288\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      5073\n",
      "           1       0.54      0.53      0.54      2673\n",
      "           2       0.23      0.27      0.25       342\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      8088\n",
      "   macro avg       0.52      0.53      0.52      8088\n",
      "weighted avg       0.68      0.68      0.68      8088\n",
      " samples avg       0.68      0.68      0.68      8088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Decision Tree + Normal Data\n",
    "X = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "35769e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7516073194856577\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      5073\n",
      "           1       0.70      0.58      0.64      2673\n",
      "           2       0.75      0.10      0.17       342\n",
      "\n",
      "   micro avg       0.79      0.75      0.77      8088\n",
      "   macro avg       0.76      0.52      0.56      8088\n",
      "weighted avg       0.79      0.75      0.76      8088\n",
      " samples avg       0.75      0.75      0.75      8088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Random Forest + Normal Data -> Promising results but low f1-score and recall\n",
    "X = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3518ab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40437, 22)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cc1f782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40437, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1628705",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dbn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdbn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupervisedDBNClassification\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dbn'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671858fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = data.drop(columns = ['Rainfall Amount (in) Sum', 'zones', 'Solar Radiation (MJ/m2) Sum', 'Wind Direction (deg) Avg',\n",
    "                                'ETo Grass (mm) Avg', 'Soil Temp (C) Avg'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e6ceb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Relative Humidity (%) Avg: 0.1341219121329885\n",
      "Feature Solar Radiation (w/m2) Avg: 0.09986320969529097\n",
      "Feature Wind Speed (mph) Max: 0.07142596299433619\n",
      "Feature Dew Point Temp (C) Max: 0.06416149324300434\n",
      "Feature Dew Point Temp (C) Min: 0.052197806084719515\n",
      "Feature Temp @ 60cm (C) Min: 0.05217203372806191\n",
      "Feature Soil Temp (C) Min: 0.04877560552835999\n",
      "Feature Soil Temp (C) Max: 0.04779998295404712\n",
      "Feature Temp @ 60cm (C) Max: 0.046961112227920716\n",
      "Feature Temp @ 10m (C) Min: 0.04597492427964966\n",
      "Feature Wind Speed (mph) Avg: 0.045857246887725474\n",
      "Feature Dew Point Temp (C) Avg: 0.045487765218100135\n",
      "Feature Temp @ 10m (C) Max: 0.04357619110617655\n",
      "Feature Temp @ 2m (C) Max: 0.04242638054775218\n",
      "Feature Temp @ 2m (C) Min: 0.04163205327776922\n",
      "Feature Temp @ 2m (C) Avg: 0.03970310557293742\n",
      "Feature Temp @ 60cm (C) Avg: 0.03938453261644333\n",
      "Feature Temp @ 10m (C) Avg: 0.03847868190471666\n"
     ]
    }
   ],
   "source": [
    "# Showing the weight each feature has for RandomForestClassifier -> Humidity seems like only true predictor\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    " \n",
    "feature_names = X_reduced.columns\n",
    "\n",
    " \n",
    "sorted_idx = feature_importance.argsort()[::-1]\n",
    "\n",
    " \n",
    "for i in range(len(sorted_idx)):\n",
    "    print(f\"Feature {feature_names[sorted_idx[i]]}: {feature_importance[sorted_idx[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81981cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.0-py3-none-win_amd64.whl (99.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rober\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\rober\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "edf970ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7818166831519947\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      7622\n",
      "           1       0.68      0.64      0.66      3956\n",
      "           2       0.57      0.16      0.24       554\n",
      "\n",
      "    accuracy                           0.78     12132\n",
      "   macro avg       0.70      0.57      0.59     12132\n",
      "weighted avg       0.77      0.78      0.77     12132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# XGB + Normal Data\n",
    "X_np = X.to_numpy()\n",
    "y_encoded_np = y_encoded.to_numpy()\n",
    "\n",
    "\n",
    "X_reshaped = X_np.reshape(-1, 22)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded_np, test_size=0.3, random_state=42, stratify=y_encoded_np)\n",
    "\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    objective='multi:softmax',  \n",
    "    num_class=3,              \n",
    "    random_state=42)          \n",
    "\n",
    "clf.fit(X_train, np.argmax(y_train, axis=1))  \n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "report = classification_report(y_test_labels, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db627dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6745796241345203\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      5081\n",
      "           1       0.65      0.50      0.56      2638\n",
      "           2       0.38      0.37      0.38       369\n",
      "\n",
      "   micro avg       0.79      0.67      0.73      8088\n",
      "   macro avg       0.64      0.55      0.59      8088\n",
      "weighted avg       0.78      0.67      0.72      8088\n",
      " samples avg       0.67      0.67      0.67      8088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# RandomForest + SMOTE + RandomUnderSampler\n",
    "X_np = X.to_numpy()\n",
    "y_encoded_np = y_encoded.to_numpy()\n",
    "\n",
    "\n",
    "X_reshaped = X_np.reshape(-1, 22)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded_np, test_size=0.2, random_state=42, stratify=y_encoded_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resampling_pipeline = Pipeline([\n",
    "    ('oversample', SMOTE(random_state=42)),              # Oversampling with SMOTE\n",
    "    ('undersample', RandomUnderSampler(random_state=42))  # Undersampling with RandomUnderSampler\n",
    "])\n",
    "\n",
    "# Fit and transform the training data using the resampling pipeline\n",
    "X_resampled, y_resampled = resampling_pipeline.fit_resample(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbe18c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17866\\AppData\\Local\\Temp\\ipykernel_8948\\4149922023.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data.skew().sort_values(ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rainfall Amount (in) Sum       26.049628\n",
       "Wind Speed (mph) Max            3.270177\n",
       "Wind Speed (mph) Avg            1.467519\n",
       "Wind Direction (deg) Avg        0.133901\n",
       "ETo Grass (mm) Avg              0.065837\n",
       "Solar Radiation (w/m2) Avg     -0.243588\n",
       "Solar Radiation (MJ/m2) Sum    -0.252665\n",
       "Soil Temp (C) Max              -0.392056\n",
       "Soil Temp (C) Avg              -0.617659\n",
       "Soil Temp (C) Min              -0.769518\n",
       "Temp @ 2m (C) Min              -0.930854\n",
       "Temp @ 60cm (C) Min            -0.931906\n",
       "Temp @ 10m (C) Min             -0.999021\n",
       "Temp @ 60cm (C) Avg            -1.042268\n",
       "Temp @ 60cm (C) Max            -1.068883\n",
       "Temp @ 2m (C) Avg              -1.069891\n",
       "Temp @ 10m (C) Max             -1.080656\n",
       "Relative Humidity (%) Avg      -1.082487\n",
       "Temp @ 10m (C) Avg             -1.083534\n",
       "Temp @ 2m (C) Max              -1.124639\n",
       "Dew Point Temp (C) Avg         -1.226296\n",
       "Dew Point Temp (C) Max         -1.295445\n",
       "Dew Point Temp (C) Min         -2.270755\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7250ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.0 in c:\\users\\17866\\anaconda3\\lib\\site-packages (3.20.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\17866\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f3db252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18c818fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1138/1138 [==============================] - 4s 2ms/step - loss: 0.6915 - accuracy: 0.7091 - val_loss: 0.5386 - val_accuracy: 0.7745 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5816 - accuracy: 0.7530 - val_loss: 0.5237 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5671 - accuracy: 0.7594 - val_loss: 0.5244 - val_accuracy: 0.7779 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5611 - accuracy: 0.7623 - val_loss: 0.5187 - val_accuracy: 0.7789 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5565 - accuracy: 0.7635 - val_loss: 0.5200 - val_accuracy: 0.7809 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5539 - accuracy: 0.7645 - val_loss: 0.5092 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5515 - accuracy: 0.7656 - val_loss: 0.5100 - val_accuracy: 0.7829 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7888 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5494 - accuracy: 0.7669 - val_loss: 0.5088 - val_accuracy: 0.7849 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7676 - val_loss: 0.5142 - val_accuracy: 0.7849 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7712 - val_loss: 0.5032 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7747 - val_loss: 0.5036 - val_accuracy: 0.7883 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7736 - val_loss: 0.5029 - val_accuracy: 0.7908 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7752 - val_loss: 0.5023 - val_accuracy: 0.7918 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7746 - val_loss: 0.5040 - val_accuracy: 0.7888 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7718 - val_loss: 0.5033 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7765 - val_loss: 0.5032 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7762 - val_loss: 0.5020 - val_accuracy: 0.7893 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7755 - val_loss: 0.5019 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7751 - val_loss: 0.5018 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5280 - accuracy: 0.7762 - val_loss: 0.5014 - val_accuracy: 0.7908 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7755 - val_loss: 0.5012 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7743 - val_loss: 0.5012 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7766 - val_loss: 0.5009 - val_accuracy: 0.7923 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7739 - val_loss: 0.5007 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7750 - val_loss: 0.5017 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7766 - val_loss: 0.5020 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7754 - val_loss: 0.5017 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5013 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7759 - val_loss: 0.5014 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7747 - val_loss: 0.5012 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7918 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7759 - val_loss: 0.5004 - val_accuracy: 0.7938 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5279 - accuracy: 0.7772 - val_loss: 0.5002 - val_accuracy: 0.7898 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5272 - accuracy: 0.7777 - val_loss: 0.5009 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7760 - val_loss: 0.5006 - val_accuracy: 0.7918 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5284 - accuracy: 0.7755 - val_loss: 0.4998 - val_accuracy: 0.7923 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5277 - accuracy: 0.7771 - val_loss: 0.5004 - val_accuracy: 0.7888 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5283 - accuracy: 0.7756 - val_loss: 0.4999 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5264 - accuracy: 0.7758 - val_loss: 0.5000 - val_accuracy: 0.7898 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5282 - accuracy: 0.7765 - val_loss: 0.5006 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "1138/1138 [==============================] - 3s 2ms/step - loss: 0.5266 - accuracy: 0.7783 - val_loss: 0.5017 - val_accuracy: 0.7883 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5006 - val_accuracy: 0.7903 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5272 - accuracy: 0.7785 - val_loss: 0.5026 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5258 - accuracy: 0.7775 - val_loss: 0.5004 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5269 - accuracy: 0.7763 - val_loss: 0.4995 - val_accuracy: 0.7933 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5254 - accuracy: 0.7796 - val_loss: 0.4991 - val_accuracy: 0.7953 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5284 - accuracy: 0.7767 - val_loss: 0.5007 - val_accuracy: 0.7933 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5253 - accuracy: 0.7779 - val_loss: 0.4991 - val_accuracy: 0.7943 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5270 - accuracy: 0.7762 - val_loss: 0.5018 - val_accuracy: 0.7923 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5246 - accuracy: 0.7783 - val_loss: 0.4999 - val_accuracy: 0.7933 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5004 - val_accuracy: 0.7938 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1138/1138 [==============================] - 3s 2ms/step - loss: 0.5244 - accuracy: 0.7795 - val_loss: 0.4997 - val_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5245 - accuracy: 0.7783 - val_loss: 0.4993 - val_accuracy: 0.7908 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5252 - accuracy: 0.7786 - val_loss: 0.4984 - val_accuracy: 0.7933 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5257 - accuracy: 0.7780 - val_loss: 0.4996 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5272 - accuracy: 0.7767 - val_loss: 0.4989 - val_accuracy: 0.7953 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5244 - accuracy: 0.7783 - val_loss: 0.4997 - val_accuracy: 0.7938 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5259 - accuracy: 0.7767 - val_loss: 0.4993 - val_accuracy: 0.7923 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5238 - accuracy: 0.7775 - val_loss: 0.4987 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5245 - accuracy: 0.7781 - val_loss: 0.4992 - val_accuracy: 0.7923 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5254 - accuracy: 0.7777 - val_loss: 0.4989 - val_accuracy: 0.7908 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7770 - val_loss: 0.4991 - val_accuracy: 0.7933 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5221 - accuracy: 0.7815 - val_loss: 0.4992 - val_accuracy: 0.7923 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1138/1138 [==============================] - 2s 2ms/step - loss: 0.5251 - accuracy: 0.7783 - val_loss: 0.5001 - val_accuracy: 0.7893 - lr: 1.0000e-04\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8066\n",
      "Test loss: 0.4775\n",
      "Test accuracy: 0.8066\n",
      "64/64 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sequential FeedForward + Normal Data + Scaled + Early Stopping -> Best model\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_normalized.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_normalized, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val_normalized, y_val), callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_normalized, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22b3dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2143/2143 [==============================] - 6s 2ms/step - loss: 0.7571 - accuracy: 0.6447 - val_loss: 0.7178 - val_accuracy: 0.6795 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6950 - accuracy: 0.6789 - val_loss: 1.3518 - val_accuracy: 0.4090 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6817 - accuracy: 0.6842 - val_loss: 0.5551 - val_accuracy: 0.7577 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6730 - accuracy: 0.6901 - val_loss: 0.7181 - val_accuracy: 0.6597 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6684 - accuracy: 0.6943 - val_loss: 0.7978 - val_accuracy: 0.6142 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6629 - accuracy: 0.6973 - val_loss: 1.0619 - val_accuracy: 0.5465 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6575 - accuracy: 0.6991 - val_loss: 0.7925 - val_accuracy: 0.6137 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6547 - accuracy: 0.7015 - val_loss: 0.6998 - val_accuracy: 0.6805 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6523 - accuracy: 0.7016 - val_loss: 0.9359 - val_accuracy: 0.5692 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6491 - accuracy: 0.7033 - val_loss: 0.5934 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6278 - accuracy: 0.7179 - val_loss: 0.6520 - val_accuracy: 0.7033 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6242 - accuracy: 0.7177 - val_loss: 0.6220 - val_accuracy: 0.7240 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "2143/2143 [==============================] - 4s 2ms/step - loss: 0.6231 - accuracy: 0.7191 - val_loss: 0.6968 - val_accuracy: 0.6761 - lr: 1.0000e-04\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7725\n",
      "Test loss: 0.5402\n",
      "Test accuracy: 0.7725\n",
      "64/64 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Sequential FeedForward + SMOTE + RandomUnderSampler\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('oversampling', SMOTE(random_state=42)),\n",
    "    ('undersampling', RandomUnderSampler(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train.values)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)))\n",
    "model.add(BatchNormalization())  \n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(y_train_resampled.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# lower learning rate when epoch > 10\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da7ac681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7425816023738873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# RBM to extract features from dataset -> fed to RandomForest\n",
    "# Normal data\n",
    "rbm = BernoulliRBM(n_components=256, learning_rate=0.1, n_iter=10)\n",
    "rbm.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_features = rbm.transform(X_train)\n",
    "X_test_features = rbm.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_combined = np.concatenate((X_train, X_train_features), axis=1)\n",
    "X_test_combined = np.concatenate((X_test, X_test_features), axis=1)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "\n",
    "accuracy = clf.score(X_test_combined, y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b27b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 3s 4ms/step - loss: 0.8679 - accuracy: 0.6716 - val_loss: 0.6473 - val_accuracy: 0.7289 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6874 - accuracy: 0.7122 - val_loss: 0.6848 - val_accuracy: 0.6737 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6568 - accuracy: 0.7147 - val_loss: 0.6281 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6314 - accuracy: 0.7305 - val_loss: 0.5929 - val_accuracy: 0.7444 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6158 - accuracy: 0.7362 - val_loss: 0.6145 - val_accuracy: 0.7276 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6042 - accuracy: 0.7423 - val_loss: 0.5854 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.6055 - accuracy: 0.7393 - val_loss: 0.6458 - val_accuracy: 0.7045 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5886 - accuracy: 0.7458 - val_loss: 0.5681 - val_accuracy: 0.7584 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5770 - accuracy: 0.7538 - val_loss: 0.5846 - val_accuracy: 0.7602 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5768 - accuracy: 0.7552 - val_loss: 0.6021 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7698 - val_loss: 0.5588 - val_accuracy: 0.7638 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7701 - val_loss: 0.5656 - val_accuracy: 0.7559 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7712 - val_loss: 0.5582 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5589 - val_accuracy: 0.7610 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7696 - val_loss: 0.5544 - val_accuracy: 0.7663 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5390 - accuracy: 0.7703 - val_loss: 0.5563 - val_accuracy: 0.7642 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5390 - accuracy: 0.7716 - val_loss: 0.5491 - val_accuracy: 0.7711 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7721 - val_loss: 0.5472 - val_accuracy: 0.7706 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7699 - val_loss: 0.5475 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5366 - accuracy: 0.7724 - val_loss: 0.5500 - val_accuracy: 0.7688 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7728 - val_loss: 0.5482 - val_accuracy: 0.7724 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7716 - val_loss: 0.5445 - val_accuracy: 0.7739 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5358 - accuracy: 0.7718 - val_loss: 0.5441 - val_accuracy: 0.7746 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7725 - val_loss: 0.5528 - val_accuracy: 0.7686 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5354 - accuracy: 0.7728 - val_loss: 0.5445 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5336 - accuracy: 0.7739 - val_loss: 0.5453 - val_accuracy: 0.7728 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 0.5332 - accuracy: 0.7743 - val_loss: 0.5476 - val_accuracy: 0.7719 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5335 - accuracy: 0.7735 - val_loss: 0.5417 - val_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5317 - accuracy: 0.7744 - val_loss: 0.5436 - val_accuracy: 0.7720 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7741 - val_loss: 0.5443 - val_accuracy: 0.7734 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5300 - accuracy: 0.7747 - val_loss: 0.5443 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7731 - val_loss: 0.5463 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5305 - accuracy: 0.7737 - val_loss: 0.5404 - val_accuracy: 0.7751 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5299 - accuracy: 0.7732 - val_loss: 0.5527 - val_accuracy: 0.7674 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5294 - accuracy: 0.7758 - val_loss: 0.5417 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5297 - accuracy: 0.7767 - val_loss: 0.5402 - val_accuracy: 0.7766 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5281 - accuracy: 0.7768 - val_loss: 0.5479 - val_accuracy: 0.7696 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5279 - accuracy: 0.7750 - val_loss: 0.5382 - val_accuracy: 0.7773 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5281 - accuracy: 0.7746 - val_loss: 0.5404 - val_accuracy: 0.7741 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 0.5287 - accuracy: 0.7746 - val_loss: 0.5417 - val_accuracy: 0.7736 - lr: 1.0000e-04\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7868\n",
      "Test loss: 0.5156\n",
      "Test accuracy: 0.7868\n",
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1D CNN, Normal data, early stopping to prevent overfitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "num_data_points, num_features = X_train.shape\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(num_data_points, num_features, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_features, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(num_features, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.5, callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb45538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1072/1072 [==============================] - 5s 3ms/step - loss: 0.5870 - accuracy: 0.7295 - val_loss: 11.6883 - val_accuracy: 0.2334 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.5144 - accuracy: 0.7577 - val_loss: 11.9106 - val_accuracy: 0.3173 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4887 - accuracy: 0.7719 - val_loss: 11.7683 - val_accuracy: 0.2720 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4706 - accuracy: 0.7792 - val_loss: 10.2868 - val_accuracy: 0.1245 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4667 - accuracy: 0.7850 - val_loss: 10.6427 - val_accuracy: 0.1261 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4541 - accuracy: 0.7907 - val_loss: 9.9193 - val_accuracy: 0.1153 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4564 - accuracy: 0.7903 - val_loss: 10.3077 - val_accuracy: 0.2834 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4493 - accuracy: 0.7947 - val_loss: 10.3678 - val_accuracy: 0.1589 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "1072/1072 [==============================] - 4s 3ms/step - loss: 0.4427 - accuracy: 0.7991 - val_loss: 11.8354 - val_accuracy: 0.2213 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4390 - accuracy: 0.8003 - val_loss: 12.2407 - val_accuracy: 0.2879 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4224 - accuracy: 0.8111 - val_loss: 12.8818 - val_accuracy: 0.2294 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "1072/1072 [==============================] - 4s 3ms/step - loss: 0.4193 - accuracy: 0.8135 - val_loss: 13.0040 - val_accuracy: 0.2126 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4185 - accuracy: 0.8130 - val_loss: 13.4460 - val_accuracy: 0.2261 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 0.4174 - accuracy: 0.8138 - val_loss: 13.1118 - val_accuracy: 0.2259 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "1072/1072 [==============================] - 4s 4ms/step - loss: 0.4168 - accuracy: 0.8138 - val_loss: 13.0275 - val_accuracy: 0.2413 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "1072/1072 [==============================] - 4s 4ms/step - loss: 0.4168 - accuracy: 0.8139 - val_loss: 13.1071 - val_accuracy: 0.2028 - lr: 1.0000e-04\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 1.0250 - accuracy: 0.7238\n",
      "Test loss: 1.0250\n",
      "Test accuracy: 0.7238\n",
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN + SMOTE + RandomUnderSampler\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('oversampling', SMOTE(random_state=42)),\n",
    "    ('undersampling', RandomUnderSampler(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train.values)\n",
    "\n",
    "\n",
    "X_train_resampled = X_train_resampled.values\n",
    "X_test = X_test.values\n",
    "\n",
    "\n",
    "num_data_points, num_features = X_train_resampled.shape\n",
    "\n",
    "\n",
    "X_train_resampled = X_train_resampled.reshape(num_data_points, num_features, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_features, 1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(num_features, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=40, batch_size=32, validation_split=0.5, callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b4322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
